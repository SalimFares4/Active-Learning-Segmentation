{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import *\n",
    "from strategies import *\n",
    "from custom_datasets import *\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "import threading\n",
    "from unet_model import *\n",
    "\n",
    "from os.path import expanduser\n",
    "from dbscan import DBScan, Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = expanduser(\"~\")\n",
    "main_path = home+\"/Active-Learning-Segmentation/\"\n",
    "dataframes_path = main_path + \"data/dataframes/\"\n",
    "sam_path = main_path + \"sam/sam_vit_h_4b8939.pth\"\n",
    "notebooks_path = main_path + \"scripts/notebooks/\"\n",
    "expirements_path = main_path+\"expirements/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_name = \"brain_df\"\n",
    "# train_df = pd.read_csv(dataframes_path+\"brain_df_train.csv\")\n",
    "# test_df = pd.read_csv(dataframes_path+\"brain_df_test.csv\")\n",
    "\n",
    "# df_name = \"lung_tumor_df\"\n",
    "# train_df = pd.read_csv(dataframes_path+\"lung_df_train.csv\")\n",
    "# test_df = pd.read_csv(dataframes_path+\"lung_df_test.csv\")\n",
    "\n",
    "df_name = \"lunar_df\"\n",
    "train_df = pd.read_csv(dataframes_path+\"lunar_df_train.csv\")\n",
    "test_df = pd.read_csv(dataframes_path+\"lunar_df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_epoch': 35,\n",
    "          'train_args':{'batch_size': 4, 'num_workers': 1},\n",
    "          'test_args':{'batch_size': 256, 'num_workers': 1},\n",
    "          'optimizer_args':{'lr': 5e-3, 'momentum': 0.9},\n",
    "          'use_sam': True,\n",
    "          'use_predictor': True,\n",
    "          'use_generator': False,\n",
    "          'init_set_size': 500,\n",
    "          'rounds': 30,\n",
    "          \"activate_sam_at_round\":1, \n",
    "          \"img_size\":(128, 128),\n",
    "          \"voting\" : True,\n",
    "          \"pre_trained\": True,\n",
    "          #Brain_MRI_segmentation\n",
    "          \"dataset\": \"Lunar_Rocky_Landscape\",\n",
    "         \"similarity_check\": True}\n",
    "\n",
    "if params[\"init_set_size\"] == len(train_df):\n",
    "    params[\"training_type\"] = \"no_active\"\n",
    "elif not params[\"use_sam\"]:\n",
    "    params[\"training_type\"] = \"no_sam\"\n",
    "elif params[\"voting\"]:\n",
    "    params[\"training_type\"] = \"voters\"\n",
    "else:\n",
    "    params[\"training_type\"]=\"withSAM_NoVoting\"\n",
    "\n",
    "if params[\"training_type\"] == \"no_active\":\n",
    "    if params[\"pre_trained\"]:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/no_active/pre_trained_Unet_{params[\"img_size\"][0]}.pt'\n",
    "    else:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/no_active/not_pre_trained_Unet_{params[\"img_size\"][0]}.pt'\n",
    "else:\n",
    "    params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/{params[\"training_type\"]}/{params[\"init_set_size\"]}'\n",
    "    \n",
    "params['test_set_size'] = len(test_df)\n",
    "params['df'] = df_name\n",
    "params['query_num'] = int(0.05 * params['init_set_size'])\n",
    "if params['query_num'] == 0:\n",
    "    params['query_num'] = 1\n",
    "params[\"strategy\"] = \"MarginSampling\"\n",
    "\n",
    "if params[\"training_type\"] == \"voters\":\n",
    "    params[\"model_path\"] = f'{params[\"model_path\"]}/voters_{params[\"img_size\"][0]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(handler, train_df, test_df):\n",
    "    return Data(train_df[\"images\"].to_list(), train_df[\"masks\"].to_list(), test_df[\"images\"].to_list(), test_df[\"masks\"].to_list(), handler, img_size=params[\"img_size\"], df=train_df, path= main_path+\"/data/processed/\", use_sam=params['use_sam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(Handler, train_df, test_df)\n",
    "data.initialize_labels(params[\"init_set_size\"])\n",
    "results=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [1,2,3,4,5,6,7,8,9,10]:\n",
    "#     model = smp.create_model(\n",
    "#             'Unet', encoder_name='resnet34', in_channels=3, classes = 1\n",
    "#         )\n",
    "#     torch.save(model.state_dict(), f\"trained_models/voters/voters_128_0/model_{i}.pt\")\n",
    "#     print(f\"Model_{i}'s training saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def ensemble(models_num, starting_index, params, data, cuurent_round=1, query_idxs=None):\n",
    "#     for i in range(starting_index, models_num+starting_index):\n",
    "#         print(f\"Model_{i}'s training started!\", flush=True)\n",
    "#         model = smp.create_model(\n",
    "#                 'Unet', encoder_name='resnet34', in_channels=3, classes = 1\n",
    "#             )\n",
    "#         init_state_Unet = torch.load(f\"trained_models/voters/voters_128_0/model_{i}.pt\")\n",
    "#         net = Net(model, params, device = torch.device(\"cuda\"))\n",
    "#         net.net.load_state_dict(init_state_Unet)\n",
    "#         strategy = MarginSampling(dataset=data, net=net, sam=None, params=params)\n",
    "#         if not query_idxs is None:\n",
    "#             strategy.update(query_idxs)\n",
    "        \n",
    "#         strategy.train()\n",
    "#         torch.save( strategy.net.net.state_dict(), f'{params[\"voters\"]}{cuurent_round}/model_{i}.pt')\n",
    "#         logits, mask_gt = strategy.predict(data.get_test_data())\n",
    "#         iou_score, accuracy, precision, recall, f1_score = data.cal_test_metrics(logits, mask_gt )\n",
    "#         print(f\"Testing metrics for model_{i}: iou_score = {iou_score:.2f}, accuracy = {accuracy:.2f}, precision = {precision:.2f}, recall = {recall:.2f}, f1_score = {f1_score:.2f}\", flush=True)\n",
    "#         print(f\"Model_{i}'s saved!\", flush=True)\n",
    "#     # print(\"Done!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_idxs = [1656,  121,  253,  968, 2095]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble(models_num=1, starting_index=3, params=params, data=data, cuurent_round=1, query_idxs=query_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i in range(1, 11):\n",
    "# for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "#     t = threading.Thread(target=ensemble, daemon=True, args=[1, i, params, data, 1, query_idxs])\n",
    "#     t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = threading.Thread(target=ensemble, daemon=True, args=[5, 1, params, data, query_idxs])\n",
    "# t1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t2 = threading.Thread(target=ensemble, daemon=True, args=[5, 6, params, data, query_idxs])\n",
    "# t2.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"pre_trained\"]:\n",
    "    model = smp.create_model('Unet', encoder_name='resnet34', in_channels=3, classes = 1)\n",
    "else:\n",
    "    model = UNet(n_channels=3, n_classes=1, bilinear=True)\n",
    "net = Net(model, params, device = torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/Lunar_Rocky_Landscape/voters/500/voters_128'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"model_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:vy30ng8y) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cosine_similarity</td><td>█▁▃</td></tr><tr><td>dice_loss</td><td>▁█▇</td></tr><tr><td>eculidian_distance</td><td>▁▁▁</td></tr><tr><td>f1_score</td><td>█▁▂</td></tr><tr><td>iou_score</td><td>█▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cosine_similarity</td><td>0.59596</td></tr><tr><td>dice_loss</td><td>0.42536</td></tr><tr><td>eculidian_distance</td><td>0.08838</td></tr><tr><td>f1_score</td><td>0.57505</td></tr><tr><td>iou_score</td><td>0.40355</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-moon-31</strong> at: <a href='https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape/runs/vy30ng8y' target=\"_blank\">https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape/runs/vy30ng8y</a><br/> View project at: <a href='https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape' target=\"_blank\">https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240703_115419-vy30ng8y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:vy30ng8y). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/wandb/run-20240703_115619-rft1vpdp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape/runs/rft1vpdp' target=\"_blank\">rural-snowball-32</a></strong> to <a href='https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape' target=\"_blank\">https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape/runs/rft1vpdp' target=\"_blank\">https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape/runs/rft1vpdp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing metrics for rd=1: iou_score = 0.43, dice_loss = 0.40, cosine_similarity = 0.61, eculidian_distance = 0.88, f1_score = 0.61\n",
      "Testing metrics for rd=2: iou_score = 0.40, dice_loss = 0.43, cosine_similarity = 0.59, eculidian_distance = 0.90, f1_score = 0.57\n",
      "Testing metrics for rd=3: iou_score = 0.40, dice_loss = 0.43, cosine_similarity = 0.60, eculidian_distance = 0.90, f1_score = 0.58\n",
      "Testing metrics for rd=4: iou_score = 0.41, dice_loss = 0.42, cosine_similarity = 0.60, eculidian_distance = 0.89, f1_score = 0.58\n",
      "Testing metrics for rd=5: iou_score = 0.44, dice_loss = 0.39, cosine_similarity = 0.62, eculidian_distance = 0.87, f1_score = 0.61\n",
      "Testing metrics for rd=6: iou_score = 0.43, dice_loss = 0.40, cosine_similarity = 0.61, eculidian_distance = 0.88, f1_score = 0.60\n",
      "Testing metrics for rd=7: iou_score = 0.39, dice_loss = 0.43, cosine_similarity = 0.59, eculidian_distance = 0.90, f1_score = 0.57\n",
      "Testing metrics for rd=8: iou_score = 0.37, dice_loss = 0.46, cosine_similarity = 0.57, eculidian_distance = 0.92, f1_score = 0.54\n",
      "Testing metrics for rd=9: iou_score = 0.40, dice_loss = 0.43, cosine_similarity = 0.59, eculidian_distance = 0.91, f1_score = 0.57\n",
      "Testing metrics for rd=10: iou_score = 0.41, dice_loss = 0.42, cosine_similarity = 0.59, eculidian_distance = 0.90, f1_score = 0.58\n",
      "Testing metrics for rd=11: iou_score = 0.41, dice_loss = 0.42, cosine_similarity = 0.60, eculidian_distance = 0.89, f1_score = 0.58\n",
      "Testing metrics for rd=12: iou_score = 0.35, dice_loss = 0.49, cosine_similarity = 0.55, eculidian_distance = 0.95, f1_score = 0.51\n",
      "Testing metrics for rd=13: iou_score = 0.39, dice_loss = 0.43, cosine_similarity = 0.59, eculidian_distance = 0.90, f1_score = 0.57\n",
      "Testing metrics for rd=14: iou_score = 0.39, dice_loss = 0.44, cosine_similarity = 0.58, eculidian_distance = 0.91, f1_score = 0.56\n",
      "Testing metrics for rd=15: iou_score = 0.39, dice_loss = 0.44, cosine_similarity = 0.59, eculidian_distance = 0.91, f1_score = 0.56\n",
      "Testing metrics for rd=16: iou_score = 0.39, dice_loss = 0.44, cosine_similarity = 0.58, eculidian_distance = 0.91, f1_score = 0.56\n",
      "Testing metrics for rd=17: iou_score = 0.39, dice_loss = 0.43, cosine_similarity = 0.59, eculidian_distance = 0.90, f1_score = 0.57\n",
      "Testing metrics for rd=18: iou_score = 0.40, dice_loss = 0.43, cosine_similarity = 0.60, eculidian_distance = 0.90, f1_score = 0.57\n",
      "Testing metrics for rd=19: iou_score = 0.38, dice_loss = 0.45, cosine_similarity = 0.58, eculidian_distance = 0.91, f1_score = 0.55\n",
      "Testing metrics for rd=20: iou_score = 0.33, dice_loss = 0.51, cosine_similarity = 0.54, eculidian_distance = 0.96, f1_score = 0.49\n",
      "Testing metrics for rd=21: iou_score = 0.40, dice_loss = 0.43, cosine_similarity = 0.60, eculidian_distance = 0.90, f1_score = 0.57\n",
      "Testing metrics for rd=22: iou_score = 0.38, dice_loss = 0.45, cosine_similarity = 0.58, eculidian_distance = 0.92, f1_score = 0.55\n",
      "Testing metrics for rd=23: iou_score = 0.38, dice_loss = 0.45, cosine_similarity = 0.58, eculidian_distance = 0.92, f1_score = 0.55\n",
      "Testing metrics for rd=24: iou_score = 0.35, dice_loss = 0.48, cosine_similarity = 0.56, eculidian_distance = 0.93, f1_score = 0.52\n",
      "Testing metrics for rd=25: iou_score = 0.39, dice_loss = 0.44, cosine_similarity = 0.58, eculidian_distance = 0.91, f1_score = 0.56\n",
      "Testing metrics for rd=26: iou_score = 0.39, dice_loss = 0.44, cosine_similarity = 0.58, eculidian_distance = 0.91, f1_score = 0.56\n",
      "Testing metrics for rd=27: iou_score = 0.36, dice_loss = 0.47, cosine_similarity = 0.57, eculidian_distance = 0.93, f1_score = 0.53\n",
      "Testing metrics for rd=28: iou_score = 0.39, dice_loss = 0.44, cosine_similarity = 0.59, eculidian_distance = 0.90, f1_score = 0.56\n",
      "Testing metrics for rd=29: iou_score = 0.38, dice_loss = 0.45, cosine_similarity = 0.58, eculidian_distance = 0.91, f1_score = 0.55\n",
      "Testing metrics for rd=30: iou_score = 0.44, dice_loss = 0.39, cosine_similarity = 0.62, eculidian_distance = 0.87, f1_score = 0.61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cosine_similarity</td><td>▇▅▆▆█▇▅▄▅▆▆▁▅▅▅▅▅▆▅▁▆▄▄▃▅▄▃▅▅█</td></tr><tr><td>dice_loss</td><td>▁▃▃▃▁▁▄▅▄▃▃▇▄▄▄▄▄▄▄█▃▅▅▆▄▄▆▄▅▁</td></tr><tr><td>eculidian_distance</td><td>▂▄▃▃▁▂▄▅▄▄▃█▄▄▄▅▄▃▄█▃▅▅▆▄▅▆▄▄▁</td></tr><tr><td>f1_score</td><td>█▆▆▆██▅▄▆▆▆▂▅▅▅▅▅▅▅▁▆▄▄▃▅▅▃▅▄█</td></tr><tr><td>iou_score</td><td>█▅▆▆█▇▅▄▅▆▆▂▅▅▅▅▅▅▄▁▆▄▄▃▅▅▃▅▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cosine_similarity</td><td>0.62275</td></tr><tr><td>dice_loss</td><td>0.38845</td></tr><tr><td>eculidian_distance</td><td>0.86862</td></tr><tr><td>f1_score</td><td>0.61201</td></tr><tr><td>iou_score</td><td>0.44094</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rural-snowball-32</strong> at: <a href='https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape/runs/rft1vpdp' target=\"_blank\">https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape/runs/rft1vpdp</a><br/> View project at: <a href='https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape' target=\"_blank\">https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240703_115619-rft1vpdp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=params[\"dataset\"],\n",
    "    \n",
    "    notes = f'{params[\"training_type\"]}_{params[\"init_set_size\"]}',\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config=params    \n",
    ")\n",
    "\n",
    "for i in range(1, 31):\n",
    "    net.net.load_state_dict(torch.load(params[\"model_path\"]+f\"_{i}/main_Unet.pt\"))\n",
    "    logits, mask_gt = net.predict(data.get_test_data())\n",
    "    iou, dice_loss, cosine_similarity, eculidian_similarity, f1 = data.cal_test_metrics(logits, mask_gt )\n",
    "    wandb.log({\"iou_score\" : iou, \"dice_loss\" : dice_loss, \"cosine_similarity\" : cosine_similarity, \"eculidian_distance\" : 1-eculidian_similarity, \"f1_score\" : f1})\n",
    "    print((f\"Testing metrics for rd={i}: iou_score = {iou:.2f}, dice_loss = {dice_loss:.2f}, cosine_similarity = {cosine_similarity:.2f}, eculidian_distance = {1-eculidian_similarity:.2f}, f1_score = {f1:.2f}\"))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing metrics for model: iou_score = 0.38, dice_loss = 0.45, cosine_similarity = 0.58, eculidian_distance = 0.91, f1_score = 0.55\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, idx, params, data, current_round=1):\n",
    "    for i in idx:\n",
    "        net.net.load_state_dict(torch.load(f'{params[\"voters\"]}{current_round}/model_{i}.pt'))\n",
    "        logits, mask_gt = net.predict(data.get_test_data())\n",
    "        iou_score, accuracy, precision, recall, f1_score = data.cal_test_metrics(logits, mask_gt )\n",
    "        print((f\"Testing metrics for model_{i}: iou_score = {iou_score:.2f}, accuracy = {accuracy:.2f}, precision = {precision:.2f}, recall = {recall:.2f}, f1_score = {f1_score:.2f}\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [i for i in range(1,10)]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(net, idx, params, data, current_round=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
