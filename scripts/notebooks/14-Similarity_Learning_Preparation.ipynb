{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0bd03b5-b329-4870-a7cb-b53e20b713df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "from os.path import expanduser\n",
    "import json\n",
    "from unet_model import *\n",
    "import segmentation_models_pytorch as smp\n",
    "from scipy.spatial.distance import cdist\n",
    "from strategies import *\n",
    "from custom_datasets import *\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be3d63a-0702-49d8-ad0f-1f026be5b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = expanduser(\"~\")\n",
    "main_path = home+\"/Active-Learning-Segmentation/\"\n",
    "dataframes_path = main_path + \"data/dataframes/\"\n",
    "sam_path = main_path + \"sam/sam_vit_h_4b8939.pth\"\n",
    "notebooks_path = main_path + \"scripts/notebooks/\"\n",
    "expirements_path = main_path+\"expirements/\"\n",
    "processed_data_path = main_path + \"data/processed/\"\n",
    "trained_models = main_path + \"scripts/notebooks/trained_models/\"\n",
    "combinations_dataframe_path = dataframes_path + \"comp_df.csv\"\n",
    "similarity_train_data_path = processed_data_path + \"train_similarity/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac4f50d-edb6-452f-8f69-2f87b2fab43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97964fce-867b-4a63-bb60-ff06ca5a0d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = \"lunar_df\"\n",
    "train_df = pd.read_csv(dataframes_path+\"lunar_df_train.csv\")\n",
    "test_df = pd.read_csv(dataframes_path+\"lunar_df_test.csv\")\n",
    "comp_df = pd.read_csv(dataframes_path+\"comp_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959d22bd-45e0-4ac2-9cac-1e1dfe45da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(similarity_train_data_path):\n",
    "    os.makedirs(similarity_train_data_path)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6069169-33b7-40f7-a488-906036ebeaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"brain_params.json\", \"r\") as f:\n",
    "#     params = json.load(f)\n",
    "# with open(\"lung_params.json\", \"r\") as f:\n",
    "#     params = json.load(f)\n",
    "\n",
    "with open(\"lunar_params.json\", \"r\") as f:\n",
    "    params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae127465-db95-4a96-92b8-06ff21ee5efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_epoch': 35,\n",
       " 'train_args': {'batch_size': 16, 'num_workers': 1},\n",
       " 'test_args': {'batch_size': 512, 'num_workers': 1},\n",
       " 'optimizer_args': {'lr': 0.005, 'momentum': 0.9},\n",
       " 'use_sam': True,\n",
       " 'use_predictor': True,\n",
       " 'use_generator': False,\n",
       " 'init_set_size': 100,\n",
       " 'rounds': 15,\n",
       " 'activate_sam_at_round': 1,\n",
       " 'img_size': [128, 128],\n",
       " 'voting': True,\n",
       " 'pre_trained': False,\n",
       " 'dataset': 'Lunar_Rocky_Landscape',\n",
       " 'similarity_check': True,\n",
       " 'dropout': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ca35a28-d404-4520-9afd-a9e370821696",
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"init_set_size\"] == len(train_df):\n",
    "    params[\"training_type\"] = \"no_active\"\n",
    "elif not params[\"use_sam\"]:\n",
    "    params[\"training_type\"] = \"no_sam\"\n",
    "elif params[\"voting\"]:\n",
    "    params[\"training_type\"] = \"voters\"\n",
    "else:\n",
    "    params[\"training_type\"]=\"withSAM_NoVoting\"\n",
    "\n",
    "if params[\"training_type\"] == \"no_active\":\n",
    "    if params[\"pre_trained\"]:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/no_active/pre_trained_Unet_{params[\"img_size\"][0]}.pt'\n",
    "    else:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/no_active/not_pre_trained_Unet_{params[\"img_size\"][0]}.pt'\n",
    "else:\n",
    "    if params[\"pre_trained\"]:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/{params[\"training_type\"]}/pre_trained/{params[\"init_set_size\"]}'\n",
    "    else:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/{params[\"training_type\"]}/not_pre_trained/{params[\"init_set_size\"]}'\n",
    "\n",
    "notes = f'{params[\"training_type\"]}_{params[\"init_set_size\"]}'\n",
    "\n",
    "if params[\"dropout\"] and params[\"training_type\"] != \"voters\":\n",
    "    params[\"model_path\"] = f'{params[\"model_path\"]}_dropout'\n",
    "    notes = f\"{notes}_dropout\"\n",
    "\n",
    "params['test_set_size'] = len(test_df)\n",
    "params['df'] = df_name\n",
    "params['query_num'] = int(0.05 * params['init_set_size'])\n",
    "if params['query_num'] == 0:\n",
    "    params['query_num'] = 1\n",
    "params[\"strategy\"] = \"MarginSampling\"\n",
    "\n",
    "\n",
    "\n",
    "if params[\"training_type\"] == \"voters\":\n",
    "    if params[\"similarity_check\"]:\n",
    "        params[\"model_path\"] = f'{params[\"model_path\"]}_dbscan'\n",
    "        notes = f\"{notes}_dbscan\"\n",
    "    if params[\"dropout\"]:\n",
    "        params[\"model_path\"] = f'{params[\"model_path\"]}_dropout'\n",
    "    params[\"model_path\"] = f'{params[\"model_path\"]}/voters_{params[\"img_size\"][0]}'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75dc11fc-a4de-40fe-9871-9702c5f7d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params[\"model_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9556ba4e-e9c6-4ec9-adcf-e7a5d310e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voters = [f'{params[\"model_path\"]}_{params[\"rounds\"]-1}/model_{i}.pt' for i in range(1,10)]\n",
    "# voters.append(f'{params[\"model_path\"]}_{params[\"rounds\"]-1}/main_Unet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1d93537-5745-40ad-94cf-3f80c2623a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_slice = test_df[i:i+1]\n",
    "test_df_slice = train_df[:100]\n",
    "# def get_data(handler, train_df, test_df):\n",
    "#     return Data(train_df[\"images\"].to_list(), train_df[\"masks\"].to_list(), test_df[\"images\"].to_list(), test_df[\"masks\"].to_list(), handler, img_size=params[\"img_size\"], df=train_df, path= main_path+\"/data/processed/\", use_sam=params['use_sam'])\n",
    "\n",
    "# data = get_data(Handler, test_df_slice, test_df_slice)\n",
    "# data.initialize_labels(params[\"init_set_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95ba816e-ee4c-4682-8e3e-25843ecb56f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet(n_channels=3, n_classes=1, bilinear=True)\n",
    "# net = Net(model, params, device = torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a926deb-63b0-442c-be9b-968930af39ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sam = SAMOracle(checkpoint_path=sam_path, img_size=params[\"img_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "537c3121-b4bb-40e2-8b79-ad7d618b798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(net, model_state:str):\n",
    "#     net.net.load_state_dict(torch.load(model_state))\n",
    "#     net.clf = net.net.to(torch.device(\"cuda\"))\n",
    "#     mask = net.predict(data.get_test_data())[0]\n",
    "#     mask = (mask.squeeze().cpu().sigmoid()> 0.5).float()\n",
    "    \n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbaa5711-5259-40da-93bf-59b937b5f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_boxes(mask):\n",
    "#     if torch.is_tensor(mask):\n",
    "#         mask = mask.numpy()\n",
    "#         mask = np.array(mask, np.uint8)\n",
    "#     # _, thresh = cv2.threshold(mask, 0.5, 1, 0)\n",
    "#     contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     cnts = []\n",
    "#     for cnt in contours:\n",
    "#         x,y,w,h = cv2.boundingRect(cnt)\n",
    "#         box = np.array([x, y, x+w, y+h])\n",
    "#         cnts.append(box)\n",
    "#     return np.array(cnts)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "214e8cde-979e-49bf-b3b6-46e104fa9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_masks = [predict(net, path) for path in voters]\n",
    "# voters_masks =[]\n",
    "# for j in range(len(tmp_masks[0])):\n",
    "#     voters_masks.append([tmp_masks[i][j] for i in range(len(tmp_masks))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cddfe75-4af8-4a26-9927-78bb27845e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voters_boxes = [[get_boxes(mask) for mask in masks] for masks in voters_masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab780812-8023-4334-9399-47ce4e9fe8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths = []\n",
    "gt_paths =[]\n",
    "mask_paths_remove=[]\n",
    "for i in range(len(test_df_slice)):\n",
    "    gt_mask= np.load(test_df_slice[\"masks\"][i], allow_pickle=True)\n",
    "    if gt_mask.sum()>0:\n",
    "        for j in range(10):\n",
    "            mask_paths.append(similarity_train_data_path + f\"sam_{j}_\" + os.path.basename(test_df_slice[\"masks\"][i]))\n",
    "            gt_paths.append(test_df_slice[\"masks\"][i])\n",
    "    # else:\n",
    "    #     for j in range(10):\n",
    "    #         mask_paths_remove.append(similarity_train_data_path + f\"sam_{j}_\" + os.path.basename(test_df_slice[\"masks\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b2aeaa7-be47-4a60-8cfc-d416c756f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in mask_paths_remove:\n",
    "#     os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57bbc354-b25c-4dc6-902d-dc9c2f76184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_df = pd.DataFrame({\"mask\":mask_paths,\n",
    "#                       \"gt_mask\":gt_paths})\n",
    "\n",
    "# comp_df.to_csv(dataframes_path+\"comp_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "450753a0-d652-456a-aab7-79f619344ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # voters_sam =[[sam.get_mask(img_path=test_df_slice[\"images\"][i], boxes=box).squeeze() for box in boxes]for i,boxes in enumerate(voters_dbscan_dropout_boxes)]\n",
    "# voters_sam=[]\n",
    "# for i,boxes in enumerate(voters_boxes):\n",
    "#     tmp_sams=[]\n",
    "#     for j,box in enumerate(boxes):\n",
    "#         tmp_sam = sam.get_mask(img_path=test_df_slice[\"images\"][i], boxes=box).squeeze()\n",
    "#         tmp_sams.append(tmp_sam)\n",
    "#         path = similarity_train_data_path + f\"sam_{j}_\" + os.path.basename(test_df_slice[\"masks\"][i])\n",
    "#         np.save(path, tmp_sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8db3dfbe-c8ec-4b4c-8666-05adbaa7d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimEmbeddings(torch.nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(SimEmbeddings, self).__init__()\n",
    "        dim_2 = int(dim/2)\n",
    "        self.layer1 = torch.nn.Linear(dim, dim_2)\n",
    "        self.layer2 = torch.nn.Linear(dim_2, dim_2)\n",
    "        self.layer3 = torch.nn.Linear(dim_2, 1, bias=False)\n",
    "        self.layer4 = torch.nn.Linear(dim, 1, bias=False)\n",
    "        # self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.layer1(x)\n",
    "        # print(x1.shape)\n",
    "        x2 = self.layer2(x1)\n",
    "        # print(x2.shape)\n",
    "        x3 = self.layer3(x2)\n",
    "        # print(x3.shape)\n",
    "        x4 = self.layer4(torch.permute(x3,(0, 2, 1)))\n",
    "        # print(x4.shape)\n",
    "        return self.sigmoid(x4)\n",
    "        # return self.relu(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a82422b-9894-4525-989d-73c637789bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = SimEmbeddings(params[\"img_size\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4b7d749-159c-40da-a2fb-9dca604e9a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimNet:\n",
    "    def __init__(self, sim_model, params):\n",
    "        self.sim_model = sim_model\n",
    "        self.params = params\n",
    "        self.optimizer = optim.SGD(list(self.sim_model.parameters()),lr = 1e-5, momentum=0.9, weight_decay=1e-2)\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    def get_similarity(self, masks, gt_masks):\n",
    "        tp, fp, fn, tn = smp.metrics.get_stats(masks.long(), gt_masks.long(), mode=\"binary\", threshold=0.5)\n",
    "        iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        return iou\n",
    "\n",
    "    def train(self, data):\n",
    "        n_epoch = self.params['n_epoch']\n",
    "        self.sim_model = self.sim_model.to(\"cuda\")\n",
    "        self.sim_model.train()\n",
    "        \n",
    "        loader = DataLoader(data, shuffle=True, batch_size=64)\n",
    "        prog_bar = tqdm.tqdm(range(1, self.params[\"n_epoch\"] + 1), ncols = 100, disable = False)\n",
    "        for epoch in prog_bar:\n",
    "            for batch_idx, (x, y) in enumerate(loader):\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                # self.optimizer.zero_grad()\n",
    "                        \n",
    "                predicted_similarity = self.sim_model(x).squeeze()\n",
    "                gt_similarity = self.get_similarity(x,y).squeeze()\n",
    "                loss = self.loss_fn(predicted_similarity, gt_similarity)                \n",
    "                \n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                prog_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    def predict(self, mask_path):\n",
    "        self.sim_model = self.sim_model.to(\"cuda\")\n",
    "        self.sim_model.eval()\n",
    "        mask = torch.Tensor(np.load(mask_path, allow_pickle=True)).view(1,self.params[\"img_size\"][0],self.params[\"img_size\"][1]).cuda()\n",
    "        return self.sim_model(mask)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e3d4b38-8888-492f-bc60-8ecf2a75de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, comp_df, transform=None, target_transform=None):\n",
    "        self.comp_df = comp_df\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comp_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = torch.Tensor(np.load(self.comp_df[\"mask\"][index], allow_pickle=True))\n",
    "        label = torch.Tensor(np.load(self.comp_df[\"gt_mask\"][index], allow_pickle=True))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2533815-d24e-4c3f-896c-6653ffc562dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(comp_df=comp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba197fbc-f264-4d23-8d06-04344e412b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=100, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5977337-a05b-4255-80cc-58a10cba9660",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimNet(sim_model=SimEmbeddings(params[\"img_size\"][0]),\n",
    "             params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2fcf318-da7b-48fc-8ff9-c86cf61e3ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5016]]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 5\n",
    "net.predict(comp_df[\"mask\"][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c07a91e5-082e-4ce5-9b5d-c597299ece58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/35 [00:00<?, ?it/s]UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  0%|                                                           | 0/35 [00:10<?, ?it/s, loss=0.0204]UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([24])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "100%|██████████████████████████████████████████████████| 35/35 [00:22<00:00,  1.55it/s, loss=0.0149]\n"
     ]
    }
   ],
   "source": [
    "net.train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b86135c-a9ab-432f-8e5b-7ceea39ad947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7429]]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 5\n",
    "net.predict(comp_df[\"mask\"][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e368c2a-de3f-482f-8dd4-84e7883c186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.Tensor(np.load(comp_df[\"mask\"][idx], allow_pickle=True))\n",
    "gt_mask = torch.Tensor(np.load(comp_df[\"gt_mask\"][idx], allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "631428ce-87ea-47eb-9bd4-a32ad50d834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50e80c6c-d93f-4066-80e2-fa22689ed84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn(gt_mask.long(), mask.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b560f894-33d3-4ba1-be30-e25f80242fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6118)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_similarity(mask,gt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077a75d-e0b1-4dec-a021-acacbc545901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96e04918-9726-4cae-acdd-2c956d1c9c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sv.plot_images_grid(\n",
    "    images=[mask.cpu().numpy(), gt_mask.cpu().numpy()],\n",
    "    grid_size=(1,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb97a5df-ced9-43a5-8654-f454f4993009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
