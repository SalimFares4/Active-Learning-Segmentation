{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import *\n",
    "from strategies import *\n",
    "from custom_datasets import *\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import json\n",
    "import wandb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"/root/Master_Thesis/\"\n",
    "dataframes_path = main_path + \"data/dataframes/\"\n",
    "sam_path = main_path + \"sam/sam_vit_h_4b8939.pth\"\n",
    "voters_path = main_path + \"scripts/notebooks/trained_models/voters/\"\n",
    "expirements_path = main_path+\"expirements/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = \"brain_df\"\n",
    "train_df = pd.read_csv(dataframes_path+\"brain_df_train.csv\")\n",
    "test_df = pd.read_csv(dataframes_path+\"brain_df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_epoch': 35, 'train_args': {'batch_size': 4, 'num_workers': 1}, 'test_args': {'batch_size': 256, 'num_workers': 1}, 'optimizer_args': {'lr': 0.005, 'momentum': 0.9}, 'use_sam': False, 'use_predictor': False, 'use_generator': False, 'init_set_size': 400, 'rounds': 23, 'activate_sam_at_round': 1, 'img_size': [128, 128]}\n"
     ]
    }
   ],
   "source": [
    "with open('params.json') as f:\n",
    "    params = json.load(f)\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_epoch': 35,\n",
    "          'train_args':{'batch_size': 4, 'num_workers': 1},\n",
    "          'test_args':{'batch_size': 256, 'num_workers': 1},\n",
    "          'optimizer_args':{'lr': 5e-3, 'momentum': 0.9},\n",
    "          'use_sam': True,\n",
    "          'use_predictor': True,\n",
    "          'use_generator': False,\n",
    "          'init_set_size': 400,\n",
    "          'rounds': 23,\n",
    "          \"activate_sam_at_round\":1, \n",
    "          \"img_size\":(128, 128)}\n",
    "\n",
    "params['test_set_size'] = len(test_df)\n",
    "params['df'] = df_name\n",
    "params['query_num'] = int(0.05 * params['init_set_size'])\n",
    "params[\"strategy\"] = \"MarginSampling\"\n",
    "params[\"voters\"] = f'trained_models/voters/voters_{params[\"img_size\"][0]}_'\n",
    "init_main_state_path = f'trained_models/voters/voters_{params[\"img_size\"][0]}_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"baseline\",\n",
    "#     resume=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaleemfares1995-sf\u001b[0m (\u001b[33mthesis_fares\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/Master_Thesis/scripts/notebooks/wandb/run-20240518_005311-a4j64yfv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thesis_fares/baseline/runs/a4j64yfv' target=\"_blank\">floral-totem-20</a></strong> to <a href='https://wandb.ai/thesis_fares/baseline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thesis_fares/baseline' target=\"_blank\">https://wandb.ai/thesis_fares/baseline</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thesis_fares/baseline/runs/a4j64yfv' target=\"_blank\">https://wandb.ai/thesis_fares/baseline/runs/a4j64yfv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/thesis_fares/baseline/runs/a4j64yfv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fba73310fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"baseline\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config=params    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trained_models/voters/voters_128_0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_main_state_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['use_sam']:\n",
    "    sam = SAMOracle(checkpoint_path=sam_path, img_size=params[\"img_size\"])\n",
    "else:\n",
    "    sam =None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from unet_model import *\n",
    "\n",
    "# model = UNet(n_channels=3, n_classes=1, bilinear=True)\n",
    "\n",
    "# init_path = 'trained_models/not_pre_trained_Unet_0.pt'\n",
    "# if not os.path.isfile(init_path):\n",
    "#     torch.save(model.state_dict(), init_path)\n",
    "    \n",
    "# init_state_Unet = torch.load(init_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.create_model(\n",
    "            'Unet', encoder_name='resnet34', in_channels=3, classes = 1\n",
    "        )\n",
    "init_path = voters_path + 'voters_128_0/main_Unet.pt'\n",
    "if not os.path.isfile(init_path):\n",
    "    if not os.path.exists(voters_path + 'voters_128_0/'):\n",
    "        os.makedirs(voters_path + 'voters_128_0/')\n",
    "    torch.save(model.state_dict(), init_path)\n",
    "init_state_Unet = torch.load(init_path)\n",
    "\n",
    "# torch.save(init_state_Unet, params[\"voters\"]+'/main_Unet.pt')\n",
    "\n",
    "net = Net(model, params, device = torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(handler, train_df, test_df):\n",
    "    return Data(train_df[\"images\"].to_list(), train_df[\"masks\"].to_list(), test_df[\"images\"].to_list(), test_df[\"masks\"].to_list(), handler, img_size=params[\"img_size\"], df=train_df, path= main_path+\"/data/processed/\", use_sam=params['use_sam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(Handler, train_df, test_df)\n",
    "data.initialize_labels(params[\"init_set_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = MarginSampling(dataset=data, net=net, sam=sam, params=params)\n",
    "# strategy.net.net.load_state_dict(init_state_Unet)\n",
    "params[\"strategy\"] = \"MarginSampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "Round 0 testing metrics: iou_score = 0.70, accuracy = 1.00, precision = 0.84, recall = 0.80, f1_score = 0.82\n",
      "Round 1\n",
      "Querying\n",
      "[ 963 1900 1899 1898 1897 1894  955 1893 1889 1888  961 1887  949 1886\n",
      " 1883 1882  968 1880 1877 1873]\n",
      "Updating with sam\n",
      "Training model_1 for voting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████▌                                    | 10/35 [01:54<04:46, 11.47s/it, loss=0.169]"
     ]
    }
   ],
   "source": [
    "logs =[]\n",
    "print(\"Round 0\")\n",
    "main_1_path = voters_path + 'voters_128_1/main_Unet.pt'\n",
    "# main_1_path = 'trained_models/No_Active_128_Unet.pt'\n",
    "# main_1_path = 'trained_models/not_pre_trained_Unet_128_done.pt'\n",
    "# main_1_path = f'trained_models/no_sam/Active_{params[\"init_set_size\"]}_no_sam_128_Unet.pt'#200, 300, 400, 500\n",
    "if not os.path.isfile(main_1_path):\n",
    "    strategy.train()\n",
    "    if not os.path.exists(voters_path + 'voters_128_1/'):\n",
    "        os.makedirs(voters_path + 'voters_128_1/')\n",
    "    torch.save(strategy.net.net.state_dict(), main_1_path)\n",
    "else:\n",
    "    strategy.net.net.load_state_dict(torch.load(main_1_path))\n",
    "    \n",
    "logits, mask_gt = strategy.predict(data.get_test_data())\n",
    "iou_score, accuracy, precision, recall, f1_score = data.cal_test_metrics(logits, mask_gt )\n",
    "wandb.log({\"iou_score\" : iou_score, \"accuracy\" : accuracy, \"precision\" : precision, \"recall\" : recall, \"f1_score\" : f1_score})\n",
    "logs.append(f\"Round 0 testing metrics: iou_score = {iou_score:.2f}, accuracy = {accuracy:.2f}, precision = {precision:.2f}, recall = {recall:.2f}, f1_score = {f1_score:.2f}\")\n",
    "print(logs[0])\n",
    "\n",
    "for rd in range(1, params[\"rounds\"]):\n",
    "    print(f\"Round {rd}\")\n",
    "\n",
    "    # query\n",
    "    print(\"Querying\")\n",
    "    query_idxs = strategy.query(params[\"query_num\"])\n",
    "    print(query_idxs)\n",
    "    # update labels\n",
    "    if params[\"use_sam\"] and rd >= params[\"activate_sam_at_round\"]:\n",
    "        print(\"Updating with sam\")\n",
    "        masks = strategy.update_voting(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "        # masks = strategy.update_weighted_voting(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "        # masks = strategy.update(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "    else:\n",
    "        print(\"Updating without sam\")\n",
    "        strategy.update(query_idxs)\n",
    "    \n",
    "    print(\"Reset and train\")\n",
    "    \n",
    "    # rd_main_path = f'trained_models/no_sam/Active_{params[\"init_set_size\"]}_{rd}_no_sam_128_Unet.pt'#200, 300, 400, 500\n",
    "    # if not os.path.isfile(rd_main_path):\n",
    "    #     strategy.net.net.load_state_dict(init_state_Unet)\n",
    "    #     strategy.train()\n",
    "    #     torch.save(strategy.net.net.state_dict(), rd_main_path)\n",
    "    # else:\n",
    "    #     strategy.net.net.load_state_dict(torch.load(rd_main_path))\n",
    "    \n",
    "    strategy.net.net.load_state_dict(init_state_Unet)\n",
    "    strategy.train()\n",
    "    main_path = f'trained_models/voters/voters_128_{rd}/'#200, 300, 400, 500\n",
    "    if not os.path.exists(main_path):\n",
    "        os.makedirs(main_path)\n",
    "    torch.save(net.net.state_dict(), main_path + 'main_Unet.pt')\n",
    "    \n",
    "    # calculate accuracy\n",
    "    logits, maks_gt = strategy.predict(data.get_test_data())\n",
    "    iou_score, accuracy, precision, recall, f1_score = data.cal_test_metrics(logits, mask_gt )\n",
    "    wandb.log({\"iou_score\" : iou_score, \"accuracy\" : accuracy, \"precision\" : precision, \"recall\" : recall, \"f1_score\" : f1_score})\n",
    "    logs.append(f\"Round {rd} testing metrics: iou_score = {iou_score:.2f}, accuracy = {accuracy:.2f}, precision = {precision:.2f}, recall = {recall:.2f}, f1_score = {f1_score:.2f}\")\n",
    "    print(logs[rd])\n",
    "    \n",
    "params['logs'] = logs\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# Path(\"./my/directory\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/Master_Thesis/scripts/notebooks'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dirname, _, filenames in os.walk(expirements_path):\n",
    "#     filename = \"expirement_{}.json\".format(len(filenames))\n",
    "#     file_path = os.path.join(dirname, filename)\n",
    "#     with open(file_path, 'w') as f:\n",
    "#         json.dump(params, f)\n",
    "#         print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy.net = net_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = torch.load('model_1.pt')\n",
    "# strategy.net.net.load_state_dict(model_1)\n",
    "# strategy.net.clf = strategy.net.net.to(torch.device(\"cuda:1\"))\n",
    "# mask_1 = strategy.predict(strategy.dataset.handler([strategy.dataset.df[\"images\"][idx]], [strategy.dataset.df[\"masks\"][idx]]))[0]\n",
    "# mask_1 = (mask_1.squeeze().cpu().sigmoid()> 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2 = torch.load('model_2.pt')\n",
    "# strategy.net.net.load_state_dict(model_2)\n",
    "# strategy.net.clf = strategy.net.net.to(torch.device(\"cuda:1\"))\n",
    "# mask_2 = strategy.predict(strategy.dataset.handler([strategy.dataset.df[\"images\"][idx]], [strategy.dataset.df[\"masks\"][idx]]))[0]\n",
    "# mask_2 = (mask_2.squeeze().cpu().sigmoid()> 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_3 = torch.load('model_3.pt')\n",
    "# strategy.net.net.load_state_dict(model_3)\n",
    "# strategy.net.clf = strategy.net.net.to(torch.device(\"cuda:1\"))\n",
    "# mask_3 = strategy.predict(strategy.dataset.handler([strategy.dataset.df[\"images\"][idx]], [strategy.dataset.df[\"masks\"][idx]]))[0]\n",
    "# mask_3 = (mask_3.squeeze().cpu().sigmoid()> 0.5).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy.net = net_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_4 = torch.load('model_4.pt')\n",
    "# strategy.net.net.load_state_dict(model_4)\n",
    "# strategy.net.clf = strategy.net.net.to(torch.device(\"cuda:1\"))\n",
    "# mask_4 = strategy.predict(strategy.dataset.handler([strategy.dataset.df[\"images\"][idx]], [strategy.dataset.df[\"masks\"][idx]]))[0]\n",
    "# mask_4 = (mask_4.squeeze().cpu().sigmoid()> 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model_states:list, idx):\n",
    "#     masks = []\n",
    "#     for state in model_states:\n",
    "#         model = torch.load(state)\n",
    "#         strategy.net.net.load_state_dict(model)\n",
    "#         strategy.net.clf = strategy.net.net.to(torch.device(\"cuda:1\"))\n",
    "#         mask = strategy.predict(strategy.dataset.handler([strategy.dataset.df[\"images\"][idx]], [strategy.dataset.df[\"masks\"][idx]]))[0]\n",
    "#         mask = (mask.squeeze().cpu().sigmoid()> 0.5).float()\n",
    "#         masks.append(mask)\n",
    "#     return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks = predict([\"model_1.pt\", \"model_2.pt\", \"model_3.pt\", \"model_4.pt\"], 2197)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import supervision as sv\n",
    "# imgs = [mask_1, mask_2, mask_3, mask_4]\n",
    "# sv.plot_images_grid(\n",
    "#     images=imgs,\n",
    "#     grid_size=(1, len(imgs)),\n",
    "#     # titles=['mask_1', 'mask_2', \"mask_3\",\"mask_4\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
