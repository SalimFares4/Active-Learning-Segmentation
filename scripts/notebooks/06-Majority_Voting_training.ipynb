{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import *\n",
    "from strategies import *\n",
    "from custom_datasets import *\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import json\n",
    "import wandb\n",
    "from unet_model import *\n",
    "from os.path import expanduser\n",
    "from dbscan import DBScan, Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = expanduser(\"~\")\n",
    "main_path = home+\"/Active-Learning-Segmentation/\"\n",
    "dataframes_path = main_path + \"data/dataframes/\"\n",
    "sam_path = main_path + \"sam/sam_vit_h_4b8939.pth\"\n",
    "notebooks_path = main_path + \"scripts/notebooks/\"\n",
    "expirements_path = main_path+\"expirements/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_name = \"brain_df\"\n",
    "# train_df = pd.read_csv(dataframes_path+\"brain_df_train.csv\")\n",
    "# test_df = pd.read_csv(dataframes_path+\"brain_df_test.csv\")\n",
    "\n",
    "df_name = \"lung_tumor_df\"\n",
    "train_df = pd.read_csv(dataframes_path+\"lung_df_train.csv\")\n",
    "test_df = pd.read_csv(dataframes_path+\"lung_df_test.csv\")\n",
    "\n",
    "# df_name = \"lunar_df\"\n",
    "# train_df = pd.read_csv(dataframes_path+\"lunar_df_train.csv\")\n",
    "# test_df = pd.read_csv(dataframes_path+\"lunar_df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2930"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6836"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"brain_params.json\", \"r\") as f:\n",
    "#     params = json.load(f)\n",
    "with open(\"lung_params.json\", \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "# with open(\"lunar_params.json\", \"r\") as f:\n",
    "#     params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"n_epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"init_set_size\"] == len(train_df):\n",
    "    params[\"training_type\"] = \"no_active\"\n",
    "elif not params[\"use_sam\"]:\n",
    "    params[\"training_type\"] = \"no_sam\"\n",
    "elif params[\"voting\"]:\n",
    "    params[\"training_type\"] = \"voters\"\n",
    "else:\n",
    "    params[\"training_type\"]=\"withSAM_NoVoting\"\n",
    "\n",
    "if params[\"training_type\"] == \"no_active\":\n",
    "    if params[\"pre_trained\"]:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/no_active/pre_trained_Unet_{params[\"img_size\"][0]}.pt'\n",
    "    else:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/no_active/not_pre_trained_Unet_{params[\"img_size\"][0]}.pt'\n",
    "else:\n",
    "    params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/{params[\"training_type\"]}/{params[\"init_set_size\"]}'\n",
    "\n",
    "if params[\"dropout\"] and params[\"training_type\"] != \"voters\":\n",
    "    params[\"model_path\"] = f'{params[\"model_path\"]}_dropout'\n",
    "\n",
    "params['test_set_size'] = len(test_df)\n",
    "params['df'] = df_name\n",
    "params['query_num'] = int(0.05 * params['init_set_size'])\n",
    "if params['query_num'] == 0:\n",
    "    params['query_num'] = 1\n",
    "params[\"strategy\"] = \"MarginSampling\"\n",
    "notes = f'{params[\"training_type\"]}_{params[\"init_set_size\"]}'\n",
    "if params[\"training_type\"] == \"voters\":\n",
    "    if params[\"similarity_check\"]:\n",
    "        params[\"model_path\"] = f'{params[\"model_path\"]}_dbscan'\n",
    "        notes = f\"{notes}_dbscan\"\n",
    "    if params[\"dropout\"]:\n",
    "        params[\"model_path\"] = f'{params[\"model_path\"]}_dropout'\n",
    "        notes = f\"{notes}_dropout\"\n",
    "    params[\"model_path\"] = f'{params[\"model_path\"]}/voters_{params[\"img_size\"][0]}'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"pre_trained\"]:\n",
    "    notes = f\"{notes}_pre_trained\"\n",
    "else:\n",
    "    notes = f\"{notes}_not_pre_trained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaleemfares1995-sf\u001b[0m (\u001b[33mthesis_fares\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/wandb/run-20240721_132246-aw8u1s0w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape/runs/aw8u1s0w' target=\"_blank\">worthy-valley-46</a></strong> to <a href='https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape' target=\"_blank\">https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape/runs/aw8u1s0w' target=\"_blank\">https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape/runs/aw8u1s0w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/thesis_fares/Lunar_Rocky_Landscape/runs/aw8u1s0w?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f5e62653040>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=params[\"dataset\"],\n",
    "    \n",
    "    notes = notes,\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config=params    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['use_sam']:\n",
    "    sam = SAMOracle(checkpoint_path=sam_path, img_size=params[\"img_size\"])\n",
    "else:\n",
    "    sam = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_init_state_not_trained saved!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models_dir = notebooks_path+\"trained_models\"\n",
    "if not os.path.exists(trained_models_dir):\n",
    "    os.makedirs(trained_models_dir)\n",
    "    \n",
    "if params[\"pre_trained\"]:\n",
    "    model = smp.create_model('Unet', encoder_name='resnet34', in_channels=3, classes = 1)\n",
    "\n",
    "    if not os.path.isfile(notebooks_path+\"trained_models/shared_init_state_pre_trained.pt\"):\n",
    "        torch.save(model.state_dict(), notebooks_path+\"trained_models/shared_init_state_pre_trained.pt\")\n",
    "        print(\"shared_init_state_pre_trained saved!\")\n",
    "    \n",
    "    init_state_Unet = torch.load(notebooks_path+\"trained_models/shared_init_state_pre_trained.pt\")\n",
    "    first_rd_Unet_path = notebooks_path+f\"trained_models/shared_1st_state_pre_trained_{params['init_set_size']}.pt\"\n",
    "else:\n",
    "    model = UNet(n_channels=3, n_classes=1, bilinear=True)\n",
    "\n",
    "    if not os.path.isfile(notebooks_path+\"trained_models/shared_init_state_not_trained.pt\"):\n",
    "        torch.save(model.state_dict(), notebooks_path+\"trained_models/shared_init_state_not_trained.pt\")\n",
    "        print(\"shared_init_state_not_trained saved!\")\n",
    "\n",
    "    init_state_Unet = torch.load(notebooks_path+\"trained_models/shared_init_state_not_trained.pt\")\n",
    "    tmp = \"trained_models/shared_1st_state_not_trained\"\n",
    "    if params[\"dropout\"]:\n",
    "        tmp= f\"{tmp}_dropout\"\n",
    "    first_rd_Unet_path = notebooks_path+f\"{tmp}_{params['init_set_size']}.pt\"\n",
    "    \n",
    "model.load_state_dict(init_state_Unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/Lunar_Rocky_Landscape/no_sam/500_dropout/Active_500_0_no_sam_128_Unet.pt  saved!\n"
     ]
    }
   ],
   "source": [
    "init_path = \"\"\n",
    "\n",
    "if params[\"training_type\"] == \"voters\":\n",
    "    init_path = params[\"model_path\"] + '_0/main_Unet.pt'\n",
    "\n",
    "elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "    init_path = params[\"model_path\"] + '/main_Unet_128_0.pt'\n",
    "    \n",
    "elif params[\"training_type\"] == \"no_sam\":\n",
    "    init_path = f'{params[\"model_path\"]}/Active_{params[\"init_set_size\"]}_{0}_no_sam_{params[\"img_size\"][0]}_Unet.pt'\n",
    "    \n",
    "if len(init_path) > 0:\n",
    "    if not os.path.isfile(init_path):\n",
    "        init_dir = os.path.dirname(init_path)\n",
    "        if not os.path.exists(init_dir):\n",
    "            os.makedirs(init_dir)#\n",
    "        torch.save(model.state_dict(), init_path)\n",
    "        print(init_path, \" saved!\")\n",
    "    # init_state_Unet = torch.load(init_path)\n",
    "    # model.load_state_dict(init_state_Unet)\n",
    "    \n",
    "\n",
    "\n",
    "net = Net(model, params, device = torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/Lunar_Rocky_Landscape/no_sam/500_dropout/Active_500_0_no_sam_128_Unet.pt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(handler, train_df, test_df):\n",
    "    return Data(train_df[\"images\"].to_list(), train_df[\"masks\"].to_list(), test_df[\"images\"].to_list(), test_df[\"masks\"].to_list(), handler, img_size=params[\"img_size\"], df=train_df, path= main_path+\"/data/processed/\", use_sam=params['use_sam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(Handler, train_df, test_df)\n",
    "data.initialize_labels(params[\"init_set_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Similarities()\n",
    "# cosine_similarity, iou_score\n",
    "db_scan = DBScan(similarities = [sim.iou_score],eps = 0.45, min_samples = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = MarginSampling(dataset=data, net=net, sam=sam, db_scan=db_scan, params=params)\n",
    "params[\"strategy\"] = \"MarginSampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/shared_1st_state_not_trained_dropout_500.pt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_rd_Unet_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Round 0\")\n",
    "rd = 1\n",
    "logs =[]\n",
    "main_path = \"\"\n",
    "if params[\"training_type\"] == \"no_sam\":\n",
    "    main_path = f'{params[\"model_path\"]}/Active_{params[\"init_set_size\"]}_{rd}_no_sam_{params[\"img_size\"][0]}_Unet.pt'\n",
    "\n",
    "elif params[\"training_type\"] == \"voters\":\n",
    "    main_path = f'{params[\"model_path\"]}_{rd}/main_Unet.pt'\n",
    "\n",
    "elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "    main_path = f'{params[\"model_path\"]}/main_Unet_{params[\"img_size\"][0]}_{rd}.pt'\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.isfile(first_rd_Unet_path):\n",
    "    strategy.train()\n",
    "    torch.save(strategy.net.net.state_dict(), first_rd_Unet_path)\n",
    "else:\n",
    "    strategy.net.net.load_state_dict(torch.load(first_rd_Unet_path))\n",
    "    \n",
    "if len(main_path)>0:\n",
    "    if not os.path.isfile(main_path):\n",
    "        main_dir = os.path.dirname(main_path)\n",
    "        if not os.path.exists(main_dir):\n",
    "            os.makedirs(main_dir)\n",
    "        torch.save(strategy.net.net.state_dict(), main_path)\n",
    "        print(\"Saved : \" + main_path)\n",
    "    else:\n",
    "        print(main_path)\n",
    "        \n",
    "else:\n",
    "    main_path = f'{params[\"model_path\"]}'\n",
    "    main_dir = os.path.dirname(main_path)        \n",
    "    if not os.path.exists(main_dir):\n",
    "        os.makedirs(main_dir)\n",
    "    torch.save(strategy.net.net.state_dict(), main_path)\n",
    "    \n",
    "logits, mask_gt = strategy.predict(data.get_test_data())\n",
    "iou, dice_loss, cosine_similarity, eculidian_similarity, f1 = data.cal_test_metrics(logits, mask_gt )\n",
    "# wandb.log({\"iou_score\" : iou, \"dice_loss\" : dice_loss, \"cosine_similarity\" : cosine_similarity, \"eculidian_distance\" : 1-eculidian_similarity, \"f1_score\" : f1})\n",
    "logs.append(f\"Round 0 testing metrics: iou_score = {iou:.2f}, dice_loss = {dice_loss:.2f}, cosine_similarity = {cosine_similarity:.2f}, eculidian_distance = {1-eculidian_similarity:.2f}, f1_score = {f1:.2f}\")\n",
    "print(logs[0])\n",
    "\n",
    "for rd in range(1, params[\"rounds\"]):\n",
    "    print(f\"Round {rd}\")\n",
    "    strategy.net.params['n_epoch']+=5\n",
    "    # query\n",
    "    print(\"Querying\")\n",
    "    query_idxs = strategy.query(params[\"query_num\"])\n",
    "    print(query_idxs)\n",
    "    # update labels\n",
    "    if params[\"use_sam\"] and rd >= params[\"activate_sam_at_round\"]:\n",
    "        print(\"Updating with sam\")\n",
    "        if params[\"training_type\"] == \"voters\":\n",
    "            masks = strategy.update_voting(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "        \n",
    "        elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "            masks = strategy.update(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "        # else:\n",
    "            # masks = strategy.update_weighted_voting(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "    else:\n",
    "        print(\"Updating without sam\")\n",
    "        strategy.update(query_idxs)\n",
    "    \n",
    "    print(\"Reset and train\")\n",
    "    if params[\"training_type\"] == \"no_sam\":\n",
    "        main_path = f'{params[\"model_path\"]}/Active_{params[\"init_set_size\"]}_{rd+1}_no_sam_{params[\"img_size\"][0]}_Unet.pt'\n",
    "\n",
    "    elif params[\"training_type\"] == \"voters\":\n",
    "        main_path = f'{params[\"model_path\"]}_{rd+1}/main_Unet.pt'\n",
    "\n",
    "    elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "        main_path = f'{params[\"model_path\"]}/main_Unet_{params[\"img_size\"][0]}_{rd+1}.pt'\n",
    "\n",
    "    if not os.path.isfile(main_path):\n",
    "        strategy.net.net.load_state_dict(init_state_Unet)\n",
    "        strategy.train()\n",
    "        main_dir = os.path.dirname(main_path)\n",
    "        if not os.path.exists(main_dir):\n",
    "            os.makedirs(main_dir)\n",
    "        torch.save(strategy.net.net.state_dict(), main_path)\n",
    "        print(\"Saved : \" + main_path)\n",
    "    else:\n",
    "        strategy.net.net.load_state_dict(torch.load(main_path))\n",
    "    # print(\"uncomment the block above\")\n",
    "    # strategy.net.net.load_state_dict(init_state_Unet)\n",
    "    # strategy.train()    \n",
    "\n",
    "    # calculate accuracy\n",
    "    logits, maks_gt = strategy.predict(data.get_test_data())\n",
    "    iou, dice_loss, cosine_similarity, eculidian_similarity, f1 = data.cal_test_metrics(logits, mask_gt )\n",
    "    # wandb.log({\"iou_score\" : iou, \"dice_loss\" : dice_loss, \"cosine_similarity\" : cosine_similarity, \"eculidian_distance\" : 1-eculidian_similarity, \"f1_score\" : f1})\n",
    "    logs.append(f\"Round {rd} testing metrics: iou_score = {iou:.2f}, dice_loss = {dice_loss:.2f}, cosine_similarity = {cosine_similarity:.2f}, eculidian_distance = {1-eculidian_similarity:.2f}, f1_score = {f1:.2f}\")\n",
    "    print(logs[rd])\n",
    "    \n",
    "params['logs'] = logs\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
