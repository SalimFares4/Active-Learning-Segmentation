{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import *\n",
    "from strategies import *\n",
    "from custom_datasets import *\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import json\n",
    "import wandb\n",
    "from unet_model import *\n",
    "from os.path import expanduser\n",
    "from dbscan import DBScan, Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = expanduser(\"~\")\n",
    "main_path = home+\"/Active-Learning-Segmentation/\"\n",
    "dataframes_path = main_path + \"data/dataframes/\"\n",
    "sam_path = main_path + \"sam/sam_vit_h_4b8939.pth\"\n",
    "notebooks_path = main_path + \"scripts/notebooks/\"\n",
    "expirements_path = main_path+\"expirements/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = \"brain_df\"\n",
    "train_df = pd.read_csv(dataframes_path+\"brain_df_train.csv\")\n",
    "test_df = pd.read_csv(dataframes_path+\"brain_df_test.csv\")\n",
    "\n",
    "# df_name = \"lung_tumor_df\"\n",
    "# train_df = pd.read_csv(dataframes_path+\"lung_df_train.csv\")\n",
    "# test_df = pd.read_csv(dataframes_path+\"lung_df_test.csv\")\n",
    "\n",
    "# df_name = \"lunar_df\"\n",
    "# train_df = pd.read_csv(dataframes_path+\"lunar_df_train.csv\")\n",
    "# test_df = pd.read_csv(dataframes_path+\"lunar_df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1179"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2750"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_epoch': 35,\n",
    "          'train_args':{'batch_size': 4, 'num_workers': 1},\n",
    "          'test_args':{'batch_size': 500, 'num_workers': 1},\n",
    "          'optimizer_args':{'lr': 5e-3, 'momentum': 0.9},\n",
    "          'use_sam': True,\n",
    "          'use_predictor': True,\n",
    "          'use_generator': False,\n",
    "          'init_set_size': 100,\n",
    "          'rounds': 30,\n",
    "          \"activate_sam_at_round\":1, \n",
    "          \"img_size\":(128, 128),\n",
    "          \"voting\" : True,\n",
    "          \"pre_trained\": True,\n",
    "          \"dataset\": \"Brain_Tumor_Segmentation_2\",\n",
    "          \"similarity_check\": True}\n",
    "\n",
    "if params[\"init_set_size\"] == len(train_df):\n",
    "    params[\"training_type\"] = \"no_active\"\n",
    "elif not params[\"use_sam\"]:\n",
    "    params[\"training_type\"] = \"no_sam\"\n",
    "elif params[\"voting\"]:\n",
    "    params[\"training_type\"] = \"voters\"\n",
    "else:\n",
    "    params[\"training_type\"]=\"withSAM_NoVoting\"\n",
    "\n",
    "if params[\"training_type\"] == \"no_active\":\n",
    "    if params[\"pre_trained\"]:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/no_active/pre_trained_Unet_{params[\"img_size\"][0]}.pt'\n",
    "    else:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/no_active/not_pre_trained_Unet_{params[\"img_size\"][0]}.pt'\n",
    "else:\n",
    "    params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/{params[\"training_type\"]}/{params[\"init_set_size\"]}'\n",
    "    \n",
    "params['test_set_size'] = len(test_df)\n",
    "params['df'] = df_name\n",
    "params['query_num'] = int(0.05 * params['init_set_size'])\n",
    "if params['query_num'] == 0:\n",
    "    params['query_num'] = 1\n",
    "params[\"strategy\"] = \"MarginSampling\"\n",
    "\n",
    "if params[\"training_type\"] == \"voters\":\n",
    "    if params[\"similarity_check\"]:\n",
    "        params[\"model_path\"] = f'{params[\"model_path\"]}_dbscan'\n",
    "    params[\"model_path\"] = f'{params[\"model_path\"]}/voters_{params[\"img_size\"][0]}'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/Brain_Tumor_Segmentation_2/voters/100_dbscan/voters_128'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"model_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaleemfares1995-sf\u001b[0m (\u001b[33mthesis_fares\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/wandb/run-20240702_150029-xdk3l5ei</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thesis_fares/Brain_Tumor_Segmentation_2/runs/xdk3l5ei' target=\"_blank\">royal-oath-8</a></strong> to <a href='https://wandb.ai/thesis_fares/Brain_Tumor_Segmentation_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thesis_fares/Brain_Tumor_Segmentation_2' target=\"_blank\">https://wandb.ai/thesis_fares/Brain_Tumor_Segmentation_2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thesis_fares/Brain_Tumor_Segmentation_2/runs/xdk3l5ei' target=\"_blank\">https://wandb.ai/thesis_fares/Brain_Tumor_Segmentation_2/runs/xdk3l5ei</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/thesis_fares/Brain_Tumor_Segmentation_2/runs/xdk3l5ei?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4e248a95e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=params[\"dataset\"],\n",
    "    \n",
    "    notes = f'{params[\"training_type\"]}_{params[\"init_set_size\"]}',\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config=params    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['use_sam']:\n",
    "    sam = SAMOracle(checkpoint_path=sam_path, img_size=params[\"img_size\"])\n",
    "else:\n",
    "    sam = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models_dir = notebooks_path+\"trained_models\"\n",
    "if not os.path.exists(trained_models_dir):\n",
    "    os.makedirs(trained_models_dir)\n",
    "    \n",
    "if params[\"pre_trained\"]:\n",
    "    model = smp.create_model('Unet', encoder_name='resnet34', in_channels=3, classes = 1)\n",
    "\n",
    "    if not os.path.isfile(notebooks_path+\"trained_models/shared_init_state_pre_trained.pt\"):\n",
    "        torch.save(model.state_dict(), notebooks_path+\"trained_models/shared_init_state_pre_trained.pt\")\n",
    "        print(\"shared_init_state_pre_trained saved!\")\n",
    "    \n",
    "    init_state_Unet = torch.load(notebooks_path+\"trained_models/shared_init_state_pre_trained.pt\")\n",
    "    first_rd_Unet_path = notebooks_path+f\"trained_models/shared_1st_state_pre_trained_{params['init_set_size']}.pt\"\n",
    "else:\n",
    "    model = UNet(n_channels=3, n_classes=1, bilinear=True)\n",
    "\n",
    "    if not os.path.isfile(notebooks_path+\"trained_models/shared_init_state_not_trained.pt\"):\n",
    "        torch.save(model.state_dict(), notebooks_path+\"trained_models/shared_init_state_not_trained.pt\")\n",
    "        print(\"shared_init_state_not_trained saved!\")\n",
    "\n",
    "    init_state_Unet = torch.load(notebooks_path+\"trained_models/shared_init_state_not_trained.pt\")\n",
    "    first_rd_Unet_path = notebooks_path+f\"trained_models/shared_1st_state_not_trained_{params['init_set_size']}.pt\"\n",
    "    \n",
    "model.load_state_dict(init_state_Unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_path = \"\"\n",
    "\n",
    "if params[\"training_type\"] == \"voters\":\n",
    "    init_path = params[\"model_path\"] + '_0/main_Unet.pt'\n",
    "\n",
    "elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "    init_path = params[\"model_path\"] + '/main_Unet_128_0.pt'\n",
    "    \n",
    "elif params[\"training_type\"] == \"no_sam\":\n",
    "    init_path = f'{params[\"model_path\"]}/Active_{params[\"init_set_size\"]}_{0}_no_sam_{params[\"img_size\"][0]}_Unet.pt'\n",
    "    \n",
    "if len(init_path) > 0:\n",
    "    if not os.path.isfile(init_path):\n",
    "        init_dir = os.path.dirname(init_path)\n",
    "        if not os.path.exists(init_dir):\n",
    "            os.makedirs(init_dir)#\n",
    "        torch.save(model.state_dict(), init_path)\n",
    "        print(init_path, \" saved!\")\n",
    "    # init_state_Unet = torch.load(init_path)\n",
    "    # model.load_state_dict(init_state_Unet)\n",
    "    \n",
    "\n",
    "\n",
    "net = Net(model, params, device = torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/Brain_Tumor_Segmentation_2/voters/100_dbscan/voters_128_0/main_Unet.pt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(handler, train_df, test_df):\n",
    "    return Data(train_df[\"images\"].to_list(), train_df[\"masks\"].to_list(), test_df[\"images\"].to_list(), test_df[\"masks\"].to_list(), handler, img_size=params[\"img_size\"], df=train_df, path= main_path+\"/data/processed/\", use_sam=params['use_sam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(Handler, train_df, test_df)\n",
    "data.initialize_labels(params[\"init_set_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Similarities()\n",
    "# cosine_similarity, iou_score\n",
    "db_scan = DBScan(similarity = sim.iou_score,eps = 0.45, min_samples = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = MarginSampling(dataset=data, net=net, sam=sam, db_scan=db_scan, params=params)\n",
    "params[\"strategy\"] = \"MarginSampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/shared_1st_state_pre_trained_100.pt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_rd_Unet_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/Brain_Tumor_Segmentation_2/voters/100_dbscan/voters_128_1/main_Unet.pt\n",
      "Round 0 testing metrics: iou_score = 0.57, accuracy = 0.99, precision = 0.76, recall = 0.69, f1_score = 0.72\n",
      "Round 1\n",
      "Querying\n",
      "[ 773 1909 1908  751 1900]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 1 testing metrics: iou_score = 0.57, accuracy = 0.99, precision = 0.76, recall = 0.70, f1_score = 0.73\n",
      "Round 2\n",
      "Querying\n",
      "[2443 2124  628 2445  630]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 2 testing metrics: iou_score = 0.57, accuracy = 0.99, precision = 0.85, recall = 0.63, f1_score = 0.72\n",
      "Round 3\n",
      "Querying\n",
      "[1802 1597  793  514 2161]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 3 testing metrics: iou_score = 0.50, accuracy = 0.99, precision = 0.62, recall = 0.72, f1_score = 0.67\n",
      "Round 4\n",
      "Querying\n",
      "[2559 2002  861 2001  864]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 4 testing metrics: iou_score = 0.51, accuracy = 0.99, precision = 0.80, recall = 0.59, f1_score = 0.68\n",
      "Round 5\n",
      "Querying\n",
      "[2360 2357 2358 1463 2603]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 5 testing metrics: iou_score = 0.58, accuracy = 0.99, precision = 0.81, recall = 0.68, f1_score = 0.74\n",
      "Round 6\n",
      "Querying\n",
      "[2106  624 1132 2125 2123]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 6 testing metrics: iou_score = 0.57, accuracy = 1.00, precision = 0.87, recall = 0.62, f1_score = 0.73\n",
      "Round 7\n",
      "Querying\n",
      "[1800  693 1822 1816  701]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 7 testing metrics: iou_score = 0.58, accuracy = 1.00, precision = 0.84, recall = 0.65, f1_score = 0.74\n",
      "Round 8\n",
      "Querying\n",
      "[1930 1161  585 1156 1928]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 8 testing metrics: iou_score = 0.57, accuracy = 0.99, precision = 0.87, recall = 0.63, f1_score = 0.73\n",
      "Round 9\n",
      "Querying\n",
      "[ 760  743  744 2037 2031]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 9 testing metrics: iou_score = 0.58, accuracy = 0.99, precision = 0.79, recall = 0.69, f1_score = 0.74\n",
      "Round 10\n",
      "Querying\n",
      "[2348 1917  538 1746 1239]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 10 testing metrics: iou_score = 0.61, accuracy = 1.00, precision = 0.83, recall = 0.70, f1_score = 0.76\n",
      "Round 11\n",
      "Querying\n",
      "[ 817  798 2089 2086  802]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 11 testing metrics: iou_score = 0.61, accuracy = 1.00, precision = 0.83, recall = 0.69, f1_score = 0.75\n",
      "Round 12\n",
      "Querying\n",
      "[2066  821 2081 2078 2075]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 12 testing metrics: iou_score = 0.60, accuracy = 0.99, precision = 0.77, recall = 0.73, f1_score = 0.75\n",
      "Round 13\n",
      "Querying\n",
      "[1655 1669 1668  767  769]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 13 testing metrics: iou_score = 0.64, accuracy = 1.00, precision = 0.83, recall = 0.73, f1_score = 0.78\n",
      "Round 14\n",
      "Querying\n",
      "[2122 2139  865 2135  869]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 14 testing metrics: iou_score = 0.65, accuracy = 1.00, precision = 0.82, recall = 0.76, f1_score = 0.79\n",
      "Round 15\n",
      "Querying\n",
      "[ 835  810 1716  813 1713]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 15 testing metrics: iou_score = 0.63, accuracy = 1.00, precision = 0.84, recall = 0.72, f1_score = 0.78\n",
      "Round 16\n",
      "Querying\n",
      "[1786  707  712 1826 1819]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 16 testing metrics: iou_score = 0.63, accuracy = 1.00, precision = 0.85, recall = 0.71, f1_score = 0.77\n",
      "Round 17\n",
      "Querying\n",
      "[ 790  772 2199 2198  777]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 17 testing metrics: iou_score = 0.62, accuracy = 1.00, precision = 0.79, recall = 0.74, f1_score = 0.77\n",
      "Round 18\n",
      "Querying\n",
      "[1265 2412  659 1269 2409]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 18 testing metrics: iou_score = 0.65, accuracy = 1.00, precision = 0.81, recall = 0.76, f1_score = 0.78\n",
      "Round 19\n",
      "Querying\n",
      "[1595  832  833 2452  839]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 19 testing metrics: iou_score = 0.65, accuracy = 1.00, precision = 0.83, recall = 0.76, f1_score = 0.79\n",
      "Round 20\n",
      "Querying\n",
      "[ 619 2164 1137  606 2159]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 20 testing metrics: iou_score = 0.65, accuracy = 1.00, precision = 0.83, recall = 0.75, f1_score = 0.79\n",
      "Round 21\n",
      "Querying\n",
      "[1304 1321 1320 1317 1316]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 21 testing metrics: iou_score = 0.67, accuracy = 1.00, precision = 0.84, recall = 0.77, f1_score = 0.80\n",
      "Round 22\n",
      "Querying\n",
      "[ 543 1027 1026 1514 1810]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 22 testing metrics: iou_score = 0.66, accuracy = 1.00, precision = 0.84, recall = 0.75, f1_score = 0.79\n",
      "Round 23\n",
      "Querying\n",
      "[1624 2556 1631  597 2554]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 23 testing metrics: iou_score = 0.67, accuracy = 1.00, precision = 0.83, recall = 0.78, f1_score = 0.80\n",
      "Round 24\n",
      "Querying\n",
      "[ 756 1948  733  740  741]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Round 24 testing metrics: iou_score = 0.65, accuracy = 1.00, precision = 0.83, recall = 0.75, f1_score = 0.79\n",
      "Round 25\n",
      "Querying\n",
      "[1485  547 2599 1496 1495]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Saved : /home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/Brain_Tumor_Segmentation_2/voters/100_dbscan/voters_128_26/main_Unet.pt\n",
      "Round 25 testing metrics: iou_score = 0.65, accuracy = 1.00, precision = 0.84, recall = 0.75, f1_score = 0.79\n",
      "Round 26\n",
      "Querying\n",
      "[2421 1099 1101 1103 2431]\n",
      "Updating with sam\n",
      "Reset and train\n",
      "Saved : /home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/Brain_Tumor_Segmentation_2/voters/100_dbscan/voters_128_27/main_Unet.pt\n",
      "Round 26 testing metrics: iou_score = 0.66, accuracy = 1.00, precision = 0.81, recall = 0.77, f1_score = 0.79\n",
      "Round 27\n",
      "Querying\n",
      "[1172 1186 1890  572 2505]\n",
      "Updating with sam\n"
     ]
    }
   ],
   "source": [
    "print(\"Round 0\")\n",
    "rd = 1\n",
    "logs =[]\n",
    "main_path = \"\"\n",
    "if params[\"training_type\"] == \"no_sam\":\n",
    "    main_path = f'{params[\"model_path\"]}/Active_{params[\"init_set_size\"]}_{rd}_no_sam_{params[\"img_size\"][0]}_Unet.pt'\n",
    "\n",
    "elif params[\"training_type\"] == \"voters\":\n",
    "    main_path = f'{params[\"model_path\"]}_{rd}/main_Unet.pt'\n",
    "\n",
    "elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "    main_path = f'{params[\"model_path\"]}/main_Unet_{params[\"img_size\"][0]}_{rd}.pt'\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.isfile(first_rd_Unet_path):\n",
    "    strategy.train()\n",
    "    torch.save(strategy.net.net.state_dict(), first_rd_Unet_path)\n",
    "else:\n",
    "    strategy.net.net.load_state_dict(torch.load(first_rd_Unet_path))\n",
    "    \n",
    "if len(main_path)>0:\n",
    "    if not os.path.isfile(main_path):\n",
    "        main_dir = os.path.dirname(main_path)\n",
    "        if not os.path.exists(main_dir):\n",
    "            os.makedirs(main_dir)\n",
    "        torch.save(strategy.net.net.state_dict(), main_path)\n",
    "        print(\"Saved : \" + main_path)\n",
    "    else:\n",
    "        print(main_path)\n",
    "        \n",
    "else:\n",
    "    main_path = f'{params[\"model_path\"]}'\n",
    "    main_dir = os.path.dirname(main_path)        \n",
    "    if not os.path.exists(main_dir):\n",
    "        os.makedirs(main_dir)\n",
    "    torch.save(strategy.net.net.state_dict(), main_path)\n",
    "    \n",
    "logits, mask_gt = strategy.predict(data.get_test_data())\n",
    "iou_score, accuracy, precision, recall, f1_score = data.cal_test_metrics(logits, mask_gt )\n",
    "wandb.log({\"iou_score\" : iou_score, \"accuracy\" : accuracy, \"precision\" : precision, \"recall\" : recall, \"f1_score\" : f1_score})\n",
    "logs.append(f\"Round 0 testing metrics: iou_score = {iou_score:.2f}, accuracy = {accuracy:.2f}, precision = {precision:.2f}, recall = {recall:.2f}, f1_score = {f1_score:.2f}\")\n",
    "print(logs[0])\n",
    "\n",
    "for rd in range(1, params[\"rounds\"]):\n",
    "    print(f\"Round {rd}\")\n",
    "    strategy.net.params['n_epoch']+=5\n",
    "    # query\n",
    "    print(\"Querying\")\n",
    "    query_idxs = strategy.query(params[\"query_num\"])\n",
    "    print(query_idxs)\n",
    "    # update labels\n",
    "    if params[\"use_sam\"] and rd >= params[\"activate_sam_at_round\"]:\n",
    "        print(\"Updating with sam\")\n",
    "        if params[\"training_type\"] == \"voters\":\n",
    "            masks = strategy.update_voting(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "        \n",
    "        elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "            masks = strategy.update(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "        # else:\n",
    "            # masks = strategy.update_weighted_voting(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "    else:\n",
    "        print(\"Updating without sam\")\n",
    "        strategy.update(query_idxs)\n",
    "    \n",
    "    print(\"Reset and train\")\n",
    "    if params[\"training_type\"] == \"no_sam\":\n",
    "        main_path = f'{params[\"model_path\"]}/Active_{params[\"init_set_size\"]}_{rd+1}_no_sam_{params[\"img_size\"][0]}_Unet.pt'\n",
    "\n",
    "    elif params[\"training_type\"] == \"voters\":\n",
    "        main_path = f'{params[\"model_path\"]}_{rd+1}/main_Unet.pt'\n",
    "\n",
    "    elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "        main_path = f'{params[\"model_path\"]}/main_Unet_{params[\"img_size\"][0]}_{rd+1}.pt'\n",
    "\n",
    "    if not os.path.isfile(main_path):\n",
    "        strategy.net.net.load_state_dict(init_state_Unet)\n",
    "        strategy.train()\n",
    "        main_dir = os.path.dirname(main_path)\n",
    "        if not os.path.exists(main_dir):\n",
    "            os.makedirs(main_dir)\n",
    "        torch.save(strategy.net.net.state_dict(), main_path)\n",
    "        print(\"Saved : \" + main_path)\n",
    "    else:\n",
    "        strategy.net.net.load_state_dict(torch.load(main_path))\n",
    "    # print(\"uncomment the block above\")\n",
    "    # strategy.net.net.load_state_dict(init_state_Unet)\n",
    "    # strategy.train()    \n",
    "\n",
    "    # calculate accuracy\n",
    "    logits, maks_gt = strategy.predict(data.get_test_data())\n",
    "    iou_score, accuracy, precision, recall, f1_score = data.cal_test_metrics(logits, mask_gt )\n",
    "    wandb.log({\"iou_score\" : iou_score, \"accuracy\" : accuracy, \"precision\" : precision, \"recall\" : recall, \"f1_score\" : f1_score})\n",
    "    logs.append(f\"Round {rd} testing metrics: iou_score = {iou_score:.2f}, accuracy = {accuracy:.2f}, precision = {precision:.2f}, recall = {recall:.2f}, f1_score = {f1_score:.2f}\")\n",
    "    print(logs[rd])\n",
    "    \n",
    "params['logs'] = logs\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
