{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import *\n",
    "from strategies import *\n",
    "from custom_datasets import *\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import json\n",
    "import wandb\n",
    "from unet_model import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"/root/Master_Thesis/\"\n",
    "dataframes_path = main_path + \"data/dataframes/\"\n",
    "sam_path = main_path + \"sam/sam_vit_h_4b8939.pth\"\n",
    "voters_path = main_path + \"scripts/notebooks/trained_models/voters/\"\n",
    "notebooks_path = main_path + \"scripts/notebooks/\"\n",
    "expirements_path = main_path+\"expirements/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_name = \"brain_df\"\n",
    "# train_df = pd.read_csv(dataframes_path+\"brain_df_train.csv\")\n",
    "# test_df = pd.read_csv(dataframes_path+\"brain_df_test.csv\")\n",
    "\n",
    "df_name = \"lung_tumor_df\"\n",
    "train_df = pd.read_csv(dataframes_path+\"lung_df_train.csv\")\n",
    "test_df = pd.read_csv(dataframes_path+\"lung_df_test.csv\")\n",
    "\n",
    "# df_name = \"flood_df\"\n",
    "# train_df = pd.read_csv(dataframes_path+\"flood_df_train.csv\")\n",
    "# test_df = pd.read_csv(dataframes_path+\"flood_df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('params.json') as f:\n",
    "#     params = json.load(f)\n",
    "#     print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1153"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_epoch': 35,\n",
    "          'train_args':{'batch_size': 16, 'num_workers': 1},\n",
    "          'test_args':{'batch_size': 512, 'num_workers': 1},\n",
    "          'optimizer_args':{'lr': 5e-3, 'momentum': 0.9},\n",
    "          'use_sam': False,\n",
    "          'use_predictor': False,\n",
    "          'use_generator': False,\n",
    "          'init_set_size': 200,\n",
    "          'rounds': 23,\n",
    "          \"activate_sam_at_round\":1, \n",
    "          \"img_size\":(128, 128),\n",
    "          \"voting\" : False,\n",
    "          \"pre_trained\":True}\n",
    "\n",
    "if params[\"init_set_size\"] == len(train_df):\n",
    "    params[\"training_type\"] = \"no_active\"\n",
    "elif not params[\"use_sam\"]:\n",
    "    params[\"training_type\"] = \"no_sam\"\n",
    "elif params[\"voting\"]:\n",
    "    params[\"training_type\"] = \"voters\"\n",
    "else:\n",
    "    params[\"training_type\"]=\"withSAM_NoVoting\"\n",
    "\n",
    "if params[\"training_type\"] == \"no_active\":\n",
    "    if params[\"pre_trained\"]:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/no_active/'\n",
    "    else:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/no_active/'\n",
    "else:\n",
    "    params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"training_type\"]}/{params[\"init_set_size\"]}'\n",
    "    \n",
    "params['test_set_size'] = len(test_df)\n",
    "params['df'] = df_name\n",
    "params['query_num'] = int(0.05 * params['init_set_size'])\n",
    "if params['query_num'] == 0:\n",
    "    params['query_num'] = 1\n",
    "params[\"strategy\"] = \"MarginSampling\"\n",
    "\n",
    "if params[\"training_type\"] == \"voters\":\n",
    "    params[\"model_path\"] = f'{params[\"model_path\"]}/voters_{params[\"img_size\"][0]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"baseline\",\n",
    "    \n",
    "#     notes = \"SAM100-Voting\",\n",
    "\n",
    "#     # track hyperparameters and run metadata\n",
    "#     config=params    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['use_sam']:\n",
    "    sam = SAMOracle(checkpoint_path=sam_path, img_size=params[\"img_size\"])\n",
    "else:\n",
    "    sam =None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"pre_trained\"]:\n",
    "    model = smp.create_model('Unet', encoder_name='resnet34', in_channels=3, classes = 1)\n",
    "else:\n",
    "    model = UNet(n_channels=3, n_classes=1, bilinear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_path = \"\"\n",
    "\n",
    "if params[\"training_type\"] == \"voters\":\n",
    "    init_path = params[\"model_path\"] + '_0/main_Unet.pt'\n",
    "\n",
    "elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "    init_path = params[\"model_path\"] + '/main_Unet_128_0.pt'\n",
    "    \n",
    "elif params[\"training_type\"] == \"no_sam\":\n",
    "    init_path = f'{params[\"model_path\"]}/Active_{params[\"init_set_size\"]}_{0}_no_sam_{params[\"img_size\"][0]}_Unet.pt'\n",
    "    \n",
    "if len(init_path) > 0:\n",
    "    if not os.path.isfile(init_path):\n",
    "        init_dir = os.path.dirname(init_path)\n",
    "        if not os.path.exists(init_dir):\n",
    "            os.makedirs(init_dir)\n",
    "        torch.save(model.state_dict(), init_path)\n",
    "    init_state_Unet = torch.load(init_path)\n",
    "    model.load_state_dict(init_state_Unet)\n",
    "    \n",
    "\n",
    "\n",
    "net = Net(model, params, device = torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/Master_Thesis/scripts/notebooks/trained_models/no_sam/200/Active_200_0_no_sam_128_Unet.pt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(handler, train_df, test_df):\n",
    "    return Data(train_df[\"images\"].to_list(), train_df[\"masks\"].to_list(), test_df[\"images\"].to_list(), test_df[\"masks\"].to_list(), handler, img_size=params[\"img_size\"], df=train_df, path= main_path+\"/data/processed/\", use_sam=params['use_sam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(Handler, train_df, test_df)\n",
    "data.initialize_labels(params[\"init_set_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = MarginSampling(dataset=data, net=net, sam=sam, params=params)\n",
    "params[\"strategy\"] = \"MarginSampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/Master_Thesis/scripts/notebooks/trained_models/no_sam/200'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"model_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "Uncomment the block above\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 35/35 [01:36<00:00,  2.77s/it, loss=0.235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 testing metrics: iou_score = 0.63, accuracy = 1.00, precision = 0.87, recall = 0.69, f1_score = 0.77\n",
      "Round 1\n",
      "Querying\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# query\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuerying\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m query_idxs \u001b[38;5;241m=\u001b[39m \u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery_num\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(query_idxs)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# update labels\u001b[39;00m\n",
      "File \u001b[0;32m~/Master_Thesis/scripts/notebooks/../src/strategies.py:565\u001b[0m, in \u001b[0;36mMarginSampling.query\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03mSelects a subset of unlabeled samples based on margin sampling.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m    ndarray: The indices of the selected samples.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    564\u001b[0m unlabeled_idxs, unlabeled_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mget_unlabeled_data()\n\u001b[0;32m--> 565\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43munlabeled_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m probs \u001b[38;5;241m=\u001b[39m probs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(unlabeled_idxs), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    567\u001b[0m max_probabilities, _ \u001b[38;5;241m=\u001b[39m probs\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Master_Thesis/scripts/notebooks/../src/strategies.py:443\u001b[0m, in \u001b[0;36mStrategy.predict_prob\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m    434\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    Calculates the probability predictions using the network.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m        ndarray: The predicted probabilities.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m probs\n",
      "File \u001b[0;32m~/Master_Thesis/scripts/notebooks/../src/models.py:137\u001b[0m, in \u001b[0;36mNet.predict_prob\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    135\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf(x)\n\u001b[1;32m    136\u001b[0m         prob \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msigmoid(out)\n\u001b[0;32m--> 137\u001b[0m         probs[idxs] \u001b[38;5;241m=\u001b[39m \u001b[43mprob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m probs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Round 0\")\n",
    "rd = 1\n",
    "logs =[]\n",
    "main_path = \"\"\n",
    "if params[\"training_type\"] == \"no_sam\":\n",
    "    main_path = f'{params[\"model_path\"]}/Active_{params[\"init_set_size\"]}_{rd}_no_sam_{params[\"img_size\"][0]}_Unet.pt'\n",
    "\n",
    "elif params[\"training_type\"] == \"voters\":\n",
    "    main_path = f'{params[\"model_path\"]}_{rd}/main_Unet.pt'\n",
    "\n",
    "elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "    main_path = f'{params[\"model_path\"]}/main_Unet_{params[\"img_size\"][0]}_{rd}.pt'\n",
    "\n",
    "# if len(main_path)>0:\n",
    "#     if not os.path.isfile(main_path):\n",
    "#         strategy.train()\n",
    "#         main_dir = os.path.dirname(main_path)\n",
    "#         if not os.path.exists(main_dir):\n",
    "#             os.makedirs(main_dir)\n",
    "#         torch.save(strategy.net.net.state_dict(), main_path)\n",
    "#         print(\"Saved : \" + main_path)\n",
    "#     else:\n",
    "#         strategy.net.net.load_state_dict(torch.load(main_path))\n",
    "print(\"Uncomment the block above\")        \n",
    "strategy.train()\n",
    "    \n",
    "logits, mask_gt = strategy.predict(data.get_test_data())\n",
    "iou_score, accuracy, precision, recall, f1_score = data.cal_test_metrics(logits, mask_gt )\n",
    "# wandb.log({\"iou_score\" : iou_score, \"accuracy\" : accuracy, \"precision\" : precision, \"recall\" : recall, \"f1_score\" : f1_score})\n",
    "logs.append(f\"Round 0 testing metrics: iou_score = {iou_score:.2f}, accuracy = {accuracy:.2f}, precision = {precision:.2f}, recall = {recall:.2f}, f1_score = {f1_score:.2f}\")\n",
    "print(logs[0])\n",
    "\n",
    "for rd in range(1, params[\"rounds\"]):\n",
    "    print(f\"Round {rd}\")\n",
    "\n",
    "    # query\n",
    "    print(\"Querying\")\n",
    "    query_idxs = strategy.query(params[\"query_num\"])\n",
    "    print(query_idxs)\n",
    "    # update labels\n",
    "    if params[\"use_sam\"] and rd >= params[\"activate_sam_at_round\"]:\n",
    "        print(\"Updating with sam\")\n",
    "        if params[\"training_type\"] == \"voters\":\n",
    "            masks = strategy.update_voting(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "        \n",
    "        elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "            masks = strategy.update(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "        # else:\n",
    "            # masks = strategy.update_weighted_voting(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "    else:\n",
    "        print(\"Updating without sam\")\n",
    "        strategy.update(query_idxs)\n",
    "    \n",
    "    print(\"Reset and train\")\n",
    "    if params[\"training_type\"] == \"no_sam\":\n",
    "        main_path = f'{params[\"model_path\"]}/Active_{params[\"init_set_size\"]}_{rd+1}_no_sam_{params[\"img_size\"][0]}_Unet.pt'\n",
    "\n",
    "    elif params[\"training_type\"] == \"voters\":\n",
    "        main_path = f'{params[\"model_path\"]}_{rd+1}/main_Unet.pt'\n",
    "\n",
    "    elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "        main_path = f'{params[\"model_path\"]}/main_Unet_{params[\"img_size\"][0]}_{rd+1}.pt'\n",
    "\n",
    "    # if not os.path.isfile(main_path):\n",
    "    #     # strategy.net.net.load_state_dict(init_state_Unet)\n",
    "    #     strategy.train()\n",
    "    #     main_dir = os.path.dirname(main_path)\n",
    "    #     if not os.path.exists(main_dir):\n",
    "    #         os.makedirs(main_dir)\n",
    "    #     torch.save(strategy.net.net.state_dict(), main_path)\n",
    "    #     print(\"Saved : \" + main_path)\n",
    "    # else:\n",
    "    #     # strategy.net.net.load_state_dict(torch.load(main_path))\n",
    "    print(\"uncomment the block above\")\n",
    "    strategy.net.net.load_state_dict(init_state_Unet)\n",
    "    strategy.train()    \n",
    "\n",
    "    # calculate accuracy\n",
    "    logits, maks_gt = strategy.predict(data.get_test_data())\n",
    "    iou_score, accuracy, precision, recall, f1_score = data.cal_test_metrics(logits, mask_gt )\n",
    "    # wandb.log({\"iou_score\" : iou_score, \"accuracy\" : accuracy, \"precision\" : precision, \"recall\" : recall, \"f1_score\" : f1_score})\n",
    "    logs.append(f\"Round {rd} testing metrics: iou_score = {iou_score:.2f}, accuracy = {accuracy:.2f}, precision = {precision:.2f}, recall = {recall:.2f}, f1_score = {f1_score:.2f}\")\n",
    "    print(logs[rd])\n",
    "    \n",
    "params['logs'] = logs\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# Path(\"./my/directory\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/Master_Thesis/scripts/notebooks'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dirname, _, filenames in os.walk(expirements_path):\n",
    "#     filename = \"expirement_{}.json\".format(len(filenames))\n",
    "#     file_path = os.path.join(dirname, filename)\n",
    "#     with open(file_path, 'w') as f:\n",
    "#         json.dump(params, f)\n",
    "#         print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy.net = net_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = torch.load('model_1.pt')\n",
    "# strategy.net.net.load_state_dict(model_1)\n",
    "# strategy.net.clf = strategy.net.net.to(torch.device(\"cuda:1\"))\n",
    "# mask_1 = strategy.predict(strategy.dataset.handler([strategy.dataset.df[\"images\"][idx]], [strategy.dataset.df[\"masks\"][idx]]))[0]\n",
    "# mask_1 = (mask_1.squeeze().cpu().sigmoid()> 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2 = torch.load('model_2.pt')\n",
    "# strategy.net.net.load_state_dict(model_2)\n",
    "# strategy.net.clf = strategy.net.net.to(torch.device(\"cuda:1\"))\n",
    "# mask_2 = strategy.predict(strategy.dataset.handler([strategy.dataset.df[\"images\"][idx]], [strategy.dataset.df[\"masks\"][idx]]))[0]\n",
    "# mask_2 = (mask_2.squeeze().cpu().sigmoid()> 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_3 = torch.load('model_3.pt')\n",
    "# strategy.net.net.load_state_dict(model_3)\n",
    "# strategy.net.clf = strategy.net.net.to(torch.device(\"cuda:1\"))\n",
    "# mask_3 = strategy.predict(strategy.dataset.handler([strategy.dataset.df[\"images\"][idx]], [strategy.dataset.df[\"masks\"][idx]]))[0]\n",
    "# mask_3 = (mask_3.squeeze().cpu().sigmoid()> 0.5).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy.net = net_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_4 = torch.load('model_4.pt')\n",
    "# strategy.net.net.load_state_dict(model_4)\n",
    "# strategy.net.clf = strategy.net.net.to(torch.device(\"cuda:1\"))\n",
    "# mask_4 = strategy.predict(strategy.dataset.handler([strategy.dataset.df[\"images\"][idx]], [strategy.dataset.df[\"masks\"][idx]]))[0]\n",
    "# mask_4 = (mask_4.squeeze().cpu().sigmoid()> 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model_states:list, idx):\n",
    "#     masks = []\n",
    "#     for state in model_states:\n",
    "#         model = torch.load(state)\n",
    "#         strategy.net.net.load_state_dict(model)\n",
    "#         strategy.net.clf = strategy.net.net.to(torch.device(\"cuda:1\"))\n",
    "#         mask = strategy.predict(strategy.dataset.handler([strategy.dataset.df[\"images\"][idx]], [strategy.dataset.df[\"masks\"][idx]]))[0]\n",
    "#         mask = (mask.squeeze().cpu().sigmoid()> 0.5).float()\n",
    "#         masks.append(mask)\n",
    "#     return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks = predict([\"model_1.pt\", \"model_2.pt\", \"model_3.pt\", \"model_4.pt\"], 2197)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import supervision as sv\n",
    "# imgs = [mask_1, mask_2, mask_3, mask_4]\n",
    "# sv.plot_images_grid(\n",
    "#     images=imgs,\n",
    "#     grid_size=(1, len(imgs)),\n",
    "#     # titles=['mask_1', 'mask_2', \"mask_3\",\"mask_4\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
