{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import *\n",
    "from strategies import *\n",
    "from custom_datasets import *\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import json\n",
    "import wandb\n",
    "from unet_model import *\n",
    "from os.path import expanduser\n",
    "from dbscan import DBScan, Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = expanduser(\"~\")\n",
    "main_path = home+\"/Active-Learning-Segmentation/\"\n",
    "dataframes_path = main_path + \"data/dataframes/\"\n",
    "sam_path = main_path + \"sam/sam_vit_h_4b8939.pth\"\n",
    "notebooks_path = main_path + \"scripts/notebooks/\"\n",
    "expirements_path = main_path+\"expirements/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_name = \"brain_df\"\n",
    "# train_df = pd.read_csv(dataframes_path+\"brain_df_train.csv\")\n",
    "# test_df = pd.read_csv(dataframes_path+\"brain_df_test.csv\")\n",
    "\n",
    "df_name = \"lung_tumor_df\"\n",
    "train_df = pd.read_csv(dataframes_path+\"lung_df_train.csv\")\n",
    "test_df = pd.read_csv(dataframes_path+\"lung_df_test.csv\")\n",
    "\n",
    "# df_name = \"lunar_df\"\n",
    "# train_df = pd.read_csv(dataframes_path+\"lunar_df_train.csv\")\n",
    "# test_df = pd.read_csv(dataframes_path+\"lunar_df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('params.json') as f:\n",
    "#     params = json.load(f)\n",
    "#     print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1153"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_epoch': 35,\n",
    "          'train_args':{'batch_size': 4, 'num_workers': 1},\n",
    "          'test_args':{'batch_size': 500, 'num_workers': 1},\n",
    "          'optimizer_args':{'lr': 5e-3, 'momentum': 0.9},\n",
    "          'use_sam': False,\n",
    "          'use_predictor': False,\n",
    "          'use_generator': False,\n",
    "          'init_set_size': 100,\n",
    "          'rounds': 30,\n",
    "          \"activate_sam_at_round\":1, \n",
    "          \"img_size\":(128, 128),\n",
    "          \"voting\" : False,\n",
    "          \"pre_trained\": True,\n",
    "          \"dataset\": \"Lung_Tumor_Segmentation_2\",\n",
    "          \"similarity_check\": False}\n",
    "\n",
    "if params[\"init_set_size\"] == len(train_df):\n",
    "    params[\"training_type\"] = \"no_active\"\n",
    "elif not params[\"use_sam\"]:\n",
    "    params[\"training_type\"] = \"no_sam\"\n",
    "elif params[\"voting\"]:\n",
    "    params[\"training_type\"] = \"voters\"\n",
    "else:\n",
    "    params[\"training_type\"]=\"withSAM_NoVoting\"\n",
    "\n",
    "if params[\"training_type\"] == \"no_active\":\n",
    "    if params[\"pre_trained\"]:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/no_active/pre_trained_Unet_{params[\"img_size\"][0]}.pt'\n",
    "    else:\n",
    "        params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/no_active/not_pre_trained_Unet_{params[\"img_size\"][0]}.pt'\n",
    "else:\n",
    "    params[\"model_path\"] = f'{notebooks_path}trained_models/{params[\"dataset\"]}/{params[\"training_type\"]}/{params[\"init_set_size\"]}'\n",
    "    \n",
    "params['test_set_size'] = len(test_df)\n",
    "params['df'] = df_name\n",
    "params['query_num'] = int(0.05 * params['init_set_size'])\n",
    "if params['query_num'] == 0:\n",
    "    params['query_num'] = 1\n",
    "params[\"strategy\"] = \"MarginSampling\"\n",
    "\n",
    "if params[\"training_type\"] == \"voters\":\n",
    "    if params[\"similarity_check\"]:\n",
    "        params[\"model_path\"] = f'{params[\"model_path\"]}_dbscan'\n",
    "    params[\"model_path\"] = f'{params[\"model_path\"]}/voters_{params[\"img_size\"][0]}'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/Lung_Tumor_Segmentation_2/no_sam/100'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"model_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaleemfares1995-sf\u001b[0m (\u001b[33mthesis_fares\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/wandb/run-20240630_010318-6m4pcjv3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thesis_fares/Lung_Tumor_Segmentation_2/runs/6m4pcjv3' target=\"_blank\">divine-aardvark-20</a></strong> to <a href='https://wandb.ai/thesis_fares/Lung_Tumor_Segmentation_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thesis_fares/Lung_Tumor_Segmentation_2' target=\"_blank\">https://wandb.ai/thesis_fares/Lung_Tumor_Segmentation_2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thesis_fares/Lung_Tumor_Segmentation_2/runs/6m4pcjv3' target=\"_blank\">https://wandb.ai/thesis_fares/Lung_Tumor_Segmentation_2/runs/6m4pcjv3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/thesis_fares/Lung_Tumor_Segmentation_2/runs/6m4pcjv3?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fdb8e8978e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=params[\"dataset\"],\n",
    "    \n",
    "    notes = f'{params[\"training_type\"]}_{params[\"init_set_size\"]}',\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config=params    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['use_sam']:\n",
    "    sam = SAMOracle(checkpoint_path=sam_path, img_size=params[\"img_size\"])\n",
    "else:\n",
    "    sam = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models_dir = notebooks_path+\"trained_models\"\n",
    "if not os.path.exists(trained_models_dir):\n",
    "    os.makedirs(trained_models_dir)\n",
    "    \n",
    "if params[\"pre_trained\"]:\n",
    "    model = smp.create_model('Unet', encoder_name='resnet34', in_channels=3, classes = 1)\n",
    "\n",
    "    if not os.path.isfile(notebooks_path+\"trained_models/shared_init_state_pre_trained.pt\"):\n",
    "        torch.save(model.state_dict(), notebooks_path+\"trained_models/shared_init_state_pre_trained.pt\")\n",
    "    \n",
    "    init_state_Unet = torch.load(notebooks_path+\"trained_models/shared_init_state_pre_trained.pt\")\n",
    "    model.load_state_dict(init_state_Unet)\n",
    "else:\n",
    "    model = UNet(n_channels=3, n_classes=1, bilinear=True)\n",
    "\n",
    "    if not os.path.isfile(notebooks_path+\"trained_models/shared_init_state_not_trained.pt\"):\n",
    "        torch.save(model.state_dict(), notebooks_path+\"trained_models/shared_init_state_not_trained.pt\")\n",
    "\n",
    "    init_state_Unet = torch.load(notebooks_path+\"trained_models/shared_init_state_not_trained.pt\")\n",
    "    model.load_state_dict(init_state_Unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_path = \"\"\n",
    "\n",
    "if params[\"training_type\"] == \"voters\":\n",
    "    init_path = params[\"model_path\"] + '_0/main_Unet.pt'\n",
    "\n",
    "elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "    init_path = params[\"model_path\"] + '/main_Unet_128_0.pt'\n",
    "    \n",
    "elif params[\"training_type\"] == \"no_sam\":\n",
    "    init_path = f'{params[\"model_path\"]}/Active_{params[\"init_set_size\"]}_{0}_no_sam_{params[\"img_size\"][0]}_Unet.pt'\n",
    "    \n",
    "if len(init_path) > 0:\n",
    "    if not os.path.isfile(init_path):\n",
    "        init_dir = os.path.dirname(init_path)\n",
    "        if not os.path.exists(init_dir):\n",
    "            os.makedirs(init_dir)\n",
    "        torch.save(model.state_dict(), init_path)\n",
    "    init_state_Unet = torch.load(init_path)\n",
    "    model.load_state_dict(init_state_Unet)\n",
    "    \n",
    "\n",
    "\n",
    "net = Net(model, params, device = torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/Lung_Tumor_Segmentation_2/no_sam/100/Active_100_0_no_sam_128_Unet.pt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(handler, train_df, test_df):\n",
    "    return Data(train_df[\"images\"].to_list(), train_df[\"masks\"].to_list(), test_df[\"images\"].to_list(), test_df[\"masks\"].to_list(), handler, img_size=params[\"img_size\"], df=train_df, path= main_path+\"/data/processed/\", use_sam=params['use_sam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(Handler, train_df, test_df)\n",
    "data.initialize_labels(params[\"init_set_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Similarities()\n",
    "# cosine_similarity, iou_score\n",
    "db_scan = DBScan(similarity = sim.iou_score,eps = 0.45, min_samples = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = MarginSampling(dataset=data, net=net, sam=sam, db_scan=db_scan, params=params)\n",
    "params[\"strategy\"] = \"MarginSampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/Lung_Tumor_Segmentation_2/no_sam/100'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"model_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "/home/jovyan/Active-Learning-Segmentation/scripts/notebooks/trained_models/Lung_Tumor_Segmentation_2/no_sam/100/Active_100_1_no_sam_128_Unet.pt\n",
      "Round 0 testing metrics: iou_score = 0.59, accuracy = 1.00, precision = 0.82, recall = 0.67, f1_score = 0.74\n",
      "Round 1\n",
      "Querying\n",
      "[706 691 692 693 694]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 1 testing metrics: iou_score = 0.63, accuracy = 1.00, precision = 0.85, recall = 0.71, f1_score = 0.78\n",
      "Round 2\n",
      "Querying\n",
      "[697 677 678 681 683]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 2 testing metrics: iou_score = 0.56, accuracy = 1.00, precision = 0.79, recall = 0.66, f1_score = 0.72\n",
      "Round 3\n",
      "Querying\n",
      "[525 514 517 518 519]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 3 testing metrics: iou_score = 0.66, accuracy = 1.00, precision = 0.81, recall = 0.78, f1_score = 0.79\n",
      "Round 4\n",
      "Querying\n",
      "[740 716 719 720 723]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 4 testing metrics: iou_score = 0.67, accuracy = 1.00, precision = 0.83, recall = 0.78, f1_score = 0.80\n",
      "Round 5\n",
      "Querying\n",
      "[728 695 696 698 699]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 5 testing metrics: iou_score = 0.56, accuracy = 1.00, precision = 0.77, recall = 0.67, f1_score = 0.72\n",
      "Round 6\n",
      "Querying\n",
      "[541 943 533 534 535]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 6 testing metrics: iou_score = 0.59, accuracy = 1.00, precision = 0.90, recall = 0.63, f1_score = 0.74\n",
      "Round 7\n",
      "Querying\n",
      "[427 812 444 817 442]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 7 testing metrics: iou_score = 0.67, accuracy = 1.00, precision = 0.91, recall = 0.72, f1_score = 0.80\n",
      "Round 8\n",
      "Querying\n",
      "[743 700 702 708 711]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 8 testing metrics: iou_score = 0.70, accuracy = 1.00, precision = 0.87, recall = 0.78, f1_score = 0.82\n",
      "Round 9\n",
      "Querying\n",
      "[537 524 526 527 922]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 9 testing metrics: iou_score = 0.69, accuracy = 1.00, precision = 0.88, recall = 0.76, f1_score = 0.82\n",
      "Round 10\n",
      "Querying\n",
      "[508 497 498 912 501]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 10 testing metrics: iou_score = 0.68, accuracy = 1.00, precision = 0.93, recall = 0.72, f1_score = 0.81\n",
      "Round 11\n",
      "Querying\n",
      "[746 687 690 701 714]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 11 testing metrics: iou_score = 0.72, accuracy = 1.00, precision = 0.93, recall = 0.76, f1_score = 0.84\n",
      "Round 12\n",
      "Querying\n",
      "[592 579 581 584 585]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 12 testing metrics: iou_score = 0.72, accuracy = 1.00, precision = 0.91, recall = 0.77, f1_score = 0.83\n",
      "Round 13\n",
      "Querying\n",
      "[751 730 733 734 735]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 13 testing metrics: iou_score = 0.73, accuracy = 1.00, precision = 0.87, recall = 0.81, f1_score = 0.84\n",
      "Round 14\n",
      "Querying\n",
      "[770 753 754 757 758]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 14 testing metrics: iou_score = 0.71, accuracy = 1.00, precision = 0.93, recall = 0.75, f1_score = 0.83\n",
      "Round 15\n",
      "Querying\n",
      "[762 713 717 738 744]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 15 testing metrics: iou_score = 0.73, accuracy = 1.00, precision = 0.91, recall = 0.79, f1_score = 0.85\n",
      "Round 16\n",
      "Querying\n",
      "[767 686 709 745 747]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 16 testing metrics: iou_score = 0.71, accuracy = 1.00, precision = 0.94, recall = 0.74, f1_score = 0.83\n",
      "Round 17\n",
      "Querying\n",
      "[765 676 679 684 685]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 17 testing metrics: iou_score = 0.73, accuracy = 1.00, precision = 0.89, recall = 0.80, f1_score = 0.84\n",
      "Round 18\n",
      "Querying\n",
      "[1001  503  504 1004  506]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 18 testing metrics: iou_score = 0.74, accuracy = 1.00, precision = 0.93, recall = 0.79, f1_score = 0.85\n",
      "Round 19\n",
      "Querying\n",
      "[942 511 512 951 515]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 19 testing metrics: iou_score = 0.74, accuracy = 1.00, precision = 0.93, recall = 0.78, f1_score = 0.85\n",
      "Round 20\n",
      "Querying\n",
      "[ 587 1024 1023  573  576]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 20 testing metrics: iou_score = 0.73, accuracy = 1.00, precision = 0.92, recall = 0.78, f1_score = 0.84\n",
      "Round 21\n",
      "Querying\n",
      "[502 489 491 492 493]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 21 testing metrics: iou_score = 0.73, accuracy = 1.00, precision = 0.92, recall = 0.78, f1_score = 0.84\n",
      "Round 22\n",
      "Querying\n",
      "[785 761 763 772 773]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 22 testing metrics: iou_score = 0.74, accuracy = 1.00, precision = 0.90, recall = 0.81, f1_score = 0.85\n",
      "Round 23\n",
      "Querying\n",
      "[600 578 583 586 588]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 23 testing metrics: iou_score = 0.74, accuracy = 1.00, precision = 0.92, recall = 0.79, f1_score = 0.85\n",
      "Round 24\n",
      "Querying\n",
      "[794 778 779 781 783]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 24 testing metrics: iou_score = 0.62, accuracy = 1.00, precision = 0.89, recall = 0.67, f1_score = 0.77\n",
      "Round 25\n",
      "Querying\n",
      "[557 542 546 547 976]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 25 testing metrics: iou_score = 0.75, accuracy = 1.00, precision = 0.91, recall = 0.81, f1_score = 0.86\n",
      "Round 26\n",
      "Querying\n",
      "[799 776 780 786 787]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 26 testing metrics: iou_score = 0.73, accuracy = 1.00, precision = 0.93, recall = 0.78, f1_score = 0.85\n",
      "Round 27\n",
      "Querying\n",
      "[940 952 949 947 946]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 27 testing metrics: iou_score = 0.76, accuracy = 1.00, precision = 0.94, recall = 0.79, f1_score = 0.86\n",
      "Round 28\n",
      "Querying\n",
      "[463 926 923 457 921]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 28 testing metrics: iou_score = 0.63, accuracy = 1.00, precision = 0.94, recall = 0.66, f1_score = 0.77\n",
      "Round 29\n",
      "Querying\n",
      "[915 901 428 904 424]\n",
      "Updating without sam\n",
      "Reset and train\n",
      "Round 29 testing metrics: iou_score = 0.75, accuracy = 1.00, precision = 0.95, recall = 0.78, f1_score = 0.85\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▃▄▁▄▅▁▃▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▄█▇█▅█</td></tr><tr><td>f1_score</td><td>▂▄▁▅▅▁▂▅▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▃█▇█▄█</td></tr><tr><td>iou_score</td><td>▂▄▁▄▅▁▂▅▆▆▅▇▇▇▆▇▆▇▇▇▇▇▇▇▃█▇█▃█</td></tr><tr><td>precision</td><td>▃▄▂▃▄▁▆▇▅▅█▇▇▅▇▇█▆▇▇▇▇▆▇▆▇▇███</td></tr><tr><td>recall</td><td>▃▄▂▇▇▃▁▄▇▆▄▆▆█▆▇▅▇▇▇▇▇█▇▃█▇▇▂▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99892</td></tr><tr><td>f1_score</td><td>0.85439</td></tr><tr><td>iou_score</td><td>0.7458</td></tr><tr><td>precision</td><td>0.94592</td></tr><tr><td>recall</td><td>0.77902</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-aardvark-20</strong> at: <a href='https://wandb.ai/thesis_fares/Lung_Tumor_Segmentation_2/runs/6m4pcjv3' target=\"_blank\">https://wandb.ai/thesis_fares/Lung_Tumor_Segmentation_2/runs/6m4pcjv3</a><br/> View project at: <a href='https://wandb.ai/thesis_fares/Lung_Tumor_Segmentation_2' target=\"_blank\">https://wandb.ai/thesis_fares/Lung_Tumor_Segmentation_2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240630_010318-6m4pcjv3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Round 0\")\n",
    "rd = 1\n",
    "logs =[]\n",
    "main_path = \"\"\n",
    "if params[\"training_type\"] == \"no_sam\":\n",
    "    main_path = f'{params[\"model_path\"]}/Active_{params[\"init_set_size\"]}_{rd}_no_sam_{params[\"img_size\"][0]}_Unet.pt'\n",
    "\n",
    "elif params[\"training_type\"] == \"voters\":\n",
    "    main_path = f'{params[\"model_path\"]}_{rd}/main_Unet.pt'\n",
    "\n",
    "elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "    main_path = f'{params[\"model_path\"]}/main_Unet_{params[\"img_size\"][0]}_{rd}.pt'\n",
    "\n",
    "if len(main_path)>0:\n",
    "    if not os.path.isfile(main_path):\n",
    "        strategy.train()\n",
    "        main_dir = os.path.dirname(main_path)\n",
    "        if not os.path.exists(main_dir):\n",
    "            os.makedirs(main_dir)\n",
    "        torch.save(strategy.net.net.state_dict(), main_path)\n",
    "        print(\"Saved : \" + main_path)\n",
    "    else:\n",
    "        print(main_path)\n",
    "        strategy.net.net.load_state_dict(torch.load(main_path))\n",
    "else:\n",
    "    main_path = f'{params[\"model_path\"]}'\n",
    "    main_dir = os.path.dirname(main_path)        \n",
    "    strategy.train()\n",
    "    if not os.path.exists(main_dir):\n",
    "        os.makedirs(main_dir)\n",
    "    torch.save(strategy.net.net.state_dict(), main_path)\n",
    "    \n",
    "logits, mask_gt = strategy.predict(data.get_test_data())\n",
    "iou_score, accuracy, precision, recall, f1_score = data.cal_test_metrics(logits, mask_gt )\n",
    "wandb.log({\"iou_score\" : iou_score, \"accuracy\" : accuracy, \"precision\" : precision, \"recall\" : recall, \"f1_score\" : f1_score})\n",
    "logs.append(f\"Round 0 testing metrics: iou_score = {iou_score:.2f}, accuracy = {accuracy:.2f}, precision = {precision:.2f}, recall = {recall:.2f}, f1_score = {f1_score:.2f}\")\n",
    "print(logs[0])\n",
    "\n",
    "for rd in range(1, params[\"rounds\"]):\n",
    "    print(f\"Round {rd}\")\n",
    "    strategy.net.params['n_epoch']+=5\n",
    "    # query\n",
    "    print(\"Querying\")\n",
    "    query_idxs = strategy.query(params[\"query_num\"])\n",
    "    print(query_idxs)\n",
    "    # update labels\n",
    "    if params[\"use_sam\"] and rd >= params[\"activate_sam_at_round\"]:\n",
    "        print(\"Updating with sam\")\n",
    "        if params[\"training_type\"] == \"voters\":\n",
    "            masks = strategy.update_voting(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "        \n",
    "        elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "            masks = strategy.update(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "        # else:\n",
    "            # masks = strategy.update_weighted_voting(query_idxs, start_sam=True, use_predictor=params[\"use_predictor\"], use_generator=params[\"use_generator\"], round=rd)\n",
    "    else:\n",
    "        print(\"Updating without sam\")\n",
    "        strategy.update(query_idxs)\n",
    "    \n",
    "    print(\"Reset and train\")\n",
    "    if params[\"training_type\"] == \"no_sam\":\n",
    "        main_path = f'{params[\"model_path\"]}/Active_{params[\"init_set_size\"]}_{rd+1}_no_sam_{params[\"img_size\"][0]}_Unet.pt'\n",
    "\n",
    "    elif params[\"training_type\"] == \"voters\":\n",
    "        main_path = f'{params[\"model_path\"]}_{rd+1}/main_Unet.pt'\n",
    "\n",
    "    elif params[\"training_type\"] == \"withSAM_NoVoting\":\n",
    "        main_path = f'{params[\"model_path\"]}/main_Unet_{params[\"img_size\"][0]}_{rd+1}.pt'\n",
    "\n",
    "    if not os.path.isfile(main_path):\n",
    "        strategy.net.net.load_state_dict(init_state_Unet)\n",
    "        strategy.train()\n",
    "        main_dir = os.path.dirname(main_path)\n",
    "        if not os.path.exists(main_dir):\n",
    "            os.makedirs(main_dir)\n",
    "        torch.save(strategy.net.net.state_dict(), main_path)\n",
    "        print(\"Saved : \" + main_path)\n",
    "    else:\n",
    "        strategy.net.net.load_state_dict(torch.load(main_path))\n",
    "    # print(\"uncomment the block above\")\n",
    "    # strategy.net.net.load_state_dict(init_state_Unet)\n",
    "    # strategy.train()    \n",
    "\n",
    "    # calculate accuracy\n",
    "    logits, maks_gt = strategy.predict(data.get_test_data())\n",
    "    iou_score, accuracy, precision, recall, f1_score = data.cal_test_metrics(logits, mask_gt )\n",
    "    wandb.log({\"iou_score\" : iou_score, \"accuracy\" : accuracy, \"precision\" : precision, \"recall\" : recall, \"f1_score\" : f1_score})\n",
    "    logs.append(f\"Round {rd} testing metrics: iou_score = {iou_score:.2f}, accuracy = {accuracy:.2f}, precision = {precision:.2f}, recall = {recall:.2f}, f1_score = {f1_score:.2f}\")\n",
    "    print(logs[rd])\n",
    "    \n",
    "params['logs'] = logs\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
